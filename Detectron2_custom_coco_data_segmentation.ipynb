{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2_custom_coco_data_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanmed/detectron2_instance_segmentation_demo/blob/master/Detectron2_custom_coco_data_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR"
      },
      "source": [
        "!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "import torch, torchvision\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w0eqA3ECcEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb34548-56c4-44f0-9ee2-3fc5ffd39c75"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the fruits nuts segmentation dataset](https://github.com/Tony607/mmdetection_instance_segmentation_demo)\n",
        "which only has 3 classes: data, fig, and hazelnut.\n",
        "We'll train a segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have the \"data\", \"fig\" and \"hazelnut\" categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPlVyYX164Jp",
        "outputId": "d4c456c8-13c9-4107-fe0b-98805a4d9750"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWpBjumk66ZZ"
      },
      "source": [
        "#import gdown\n",
        "#import shutil\n",
        "#https://drive.google.com/file/d/14ZcrZ9JbU8_XvCkGvq00xrZt2hioZjGv/view?usp=sharing\n",
        "#url = 'https://drive.google.com/uc?id=14ZcrZ9JbU8_XvCkGvq00xrZt2hioZjGv'\n",
        "#output = 'data.zip'\n",
        "#gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvXceRn17ByN"
      },
      "source": [
        "#!unzip data.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb"
      },
      "source": [
        "# Download test set\n",
        "#https://drive.google.com/file/d/1IZpWoEfXUndLCVs0KWVnJxJuH0klxKUY/view?usp=sharing\n",
        "#url = 'https://drive.google.com/uc?id=1IZpWoEfXUndLCVs0KWVnJxJuH0klxKUY'\n",
        "#output = 'test.zip'\n",
        "#gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9_ls08j8RbV"
      },
      "source": [
        "#!unzip test.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6p8Rlh3ktoX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7195aa0f-85e5-437a-c50f-901984366404"
      },
      "source": [
        "# Download full dataset\n",
        "import gdown\n",
        "import shutil\n",
        "#https://drive.google.com/file/d/1CKo1ls81LEOBM-HDuauOT1_Tb1f3Bh2W/view?usp=sharing\n",
        "url = 'https://drive.google.com/uc?id=1CKo1ls81LEOBM-HDuauOT1_Tb1f3Bh2W'\n",
        "output = 'dataset.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CKo1ls81LEOBM-HDuauOT1_Tb1f3Bh2W\n",
            "To: /content/dataset.zip\n",
            "7.25GB [02:29, 48.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dataset.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcZOHG3KlIQx"
      },
      "source": [
        "!unzip dataset.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS6RNGRNj83n"
      },
      "source": [
        "!rm dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "rTut7JjhmXAH",
        "outputId": "49a325c9-e940-49e6-997d-4556f8485024"
      },
      "source": [
        "#download latest model\n",
        "#ttps://drive.google.com/file/d/1lhBxaXSDzc8HaJFtXfLb9qcmS3VDyDnK/view?usp=sharing\n",
        "url = \"https://drive.google.com/uc?id=1lhBxaXSDzc8HaJFtXfLb9qcmS3VDyDnK\"\n",
        "output = 'model_final.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lhBxaXSDzc8HaJFtXfLb9qcmS3VDyDnK\n",
            "To: /content/model_final.pth\n",
            "351MB [00:04, 72.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'model_final.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZexjDocemoBn"
      },
      "source": [
        "!mv model_final.pth output/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW"
      },
      "source": [
        "# Register the fruits_nuts dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnkg1PByUjGQ"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"skku_unloading_coco_train\", {}, \"./train/train.json\", \"./train/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWknKqWTWIw9"
      },
      "source": [
        "skku_train_metadata = MetadataCatalog.get(\"skku_unloading_coco_train\")\n",
        "skku_train_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--YvOJEP7q32"
      },
      "source": [
        "register_coco_instances(\"skku_unloading_coco_test\", {}, \"./test/test.json\", \"./test/\")\n",
        "skku_test_metadata = MetadataCatalog.get(\"skku_unloading_coco_test\")\n",
        "skku_test_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD59X3RufXms"
      },
      "source": [
        "register_coco_instances(\"skku_unloading_coco_val\", {}, \"./val/val.json\", \"./val/\")\n",
        "skku_val_metadata = MetadataCatalog.get(\"skku_unloading_coco_val\")\n",
        "skku_val_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_val\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkNbUzUOLYf0"
      },
      "source": [
        "import random\n",
        "\n",
        "for d in random.sample(skku_train_dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=skku_train_metadata, scale=0.35)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the fruits_nuts dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2p1U5OneZet"
      },
      "source": [
        "#Prepare tensorboard\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxczkMPwZ7zE",
        "outputId": "d09b4ff5-5837-4db5-e30d-2d1a50c8b6d8"
      },
      "source": [
        "\n",
        "LOG_DIR = '/content/output/'\n",
        "print(LOG_DIR)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/output/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUoCbV9gD-G3",
        "outputId": "58ba5377-d6f7-45d0-db4b-905f4039a890"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://a1918aaa5191.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tuGzjukEzwl"
      },
      "source": [
        "!rm -rf output/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "# Evaluation code from\n",
        "#https://github.com/facebookresearch/detectron2/issues/810#issuecomment-596194293\n",
        "\n",
        "# More detailed implementation at\n",
        "#https://medium.com/@apofeniaco/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
        "##or\n",
        "#https://tshafer.com/blog/2020/06/detectron2-eval-loss\n",
        "\n",
        "from detectron2.engine import HookBase\n",
        "from detectron2.data import build_detection_train_loader\n",
        "import detectron2.utils.comm as comm\n",
        "import torch\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "    if output_folder is None:\n",
        "      output_folder = os.path.join(cfg.OUTPUT_DIR,\"inference\")\n",
        "    return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "\n",
        "class ValidationLoss(HookBase):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg.clone()\n",
        "        self.cfg.DATASETS.TRAIN = cfg.DATASETS.VAL\n",
        "        self._loader = iter(build_detection_train_loader(self.cfg))\n",
        "        \n",
        "    def after_step(self):\n",
        "        data = next(self._loader)\n",
        "        with torch.no_grad():\n",
        "            loss_dict = self.trainer.model(data)\n",
        "            \n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in \n",
        "                                 comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                self.trainer.storage.put_scalars(total_val_loss=losses_reduced, \n",
        "                                                 **loss_dict_reduced)\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"skku_unloading_coco_train\",)\n",
        "cfg.DATASETS.TEST = (\"skku_unloading_coco_val\",)   # no metrics implemented for this dataset\n",
        "cfg.DATASETS.VAL = (\"skku_unloading_coco_val\",)   # no metrics implemented for this dataset\n",
        "cfg.TEST.EVAL_PERIOD = 200\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MAX_ITER = 3000   # 300 iterations seems good enough, but you can certainly train longer\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # 3 classes (data, fig, hazelnut)\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg) #DefaultTrainer(cfg)\n",
        "val_loss = ValidationLoss(cfg)  \n",
        "trainer.register_hooks([val_loss])\n",
        "# swap the order of PeriodicWriter and ValidationLoss\n",
        "trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]\n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJHRlEm_FMhO"
      },
      "source": [
        "!zip -r output.zip output\n",
        "from google.colab import files\n",
        "files.download('output.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvC61lS9VptR"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"skku_unloading_coco_test\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfLx83yVaOEP"
      },
      "source": [
        "Do evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKjmc5-aaNJS"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"skku_unloading_coco_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"skku_unloading_coco_test\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import random\n",
        "\n",
        "for d in random.sample(skku_test_dataset_dicts, 5):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=skku_test_metadata, \n",
        "                   scale=0.4, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bo0cypwllj"
      },
      "source": [
        "skku_train_metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6lYrCqLLLW"
      },
      "source": [
        "## Benchmark inference speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxRHYcAC_Z0f"
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vm2paQxDUMn"
      },
      "source": [
        "# Evaluate performance using pyCOCOtools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFMOqBbWEh5v"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go3Y1NuoDr2d"
      },
      "source": [
        "from pycocotools.coco import COCO \n",
        "from pycocotools.cocoeval import COCOeval \n",
        "import numpy as np \n",
        "import skimage.io as io \n",
        "import pylab,json \n",
        "from tempfile import NamedTemporaryFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtr1AwIRLxLr"
      },
      "source": [
        "def xyxy2xywh(bbox):\n",
        "        \"\"\"Convert ``xyxy`` style bounding boxes to ``xywh`` style for COCO\n",
        "        evaluation.\n",
        "\n",
        "        Args:\n",
        "            bbox (numpy.ndarray): The bounding boxes, shape (4, ), in\n",
        "                ``xyxy`` order.\n",
        "\n",
        "        Returns:\n",
        "            list[float]: The converted bounding boxes, in ``xywh`` order.\n",
        "        \"\"\"\n",
        "\n",
        "        _bbox = bbox.tolist()\n",
        "        return [\n",
        "            _bbox[0],\n",
        "            _bbox[1],\n",
        "            _bbox[2] - _bbox[0],\n",
        "            _bbox[3] - _bbox[1],\n",
        "        ] \n",
        "\n",
        "import numpy as np                                 # (pip install numpy)\n",
        "from skimage import measure                        # (pip install scikit-image)\n",
        "from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n",
        "\n",
        "def create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd, bbox):\n",
        "    # Find contours (boundary lines) around each sub-mask\n",
        "    # Note: there could be multiple contours if the object\n",
        "    # is partially occluded. (E.g. an elephant behind a tree)\n",
        "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
        "\n",
        "    segmentations = []\n",
        "    polygons = []\n",
        "    #print(len(contours))\n",
        "    for contour in contours:\n",
        "        # Flip from (row, col) representation to (x, y)\n",
        "        # and subtract the padding pixel\n",
        "        for i in range(len(contour)):\n",
        "            row, col = contour[i]\n",
        "            contour[i] = (col - 1, row - 1)\n",
        "\n",
        "        # Make a polygon and simplify it\n",
        "        poly = Polygon(contour)\n",
        "        poly = poly.simplify(1.0, preserve_topology=False)\n",
        "        polygons.append(poly)\n",
        "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
        "        if len(segmentation) > 4:\n",
        "          segmentations.append(segmentation)\n",
        "\n",
        "    # Combine the polygons to calculate the bounding box and area\n",
        "    multi_poly = MultiPolygon(polygons)\n",
        "    #x, y, max_x, max_y = multi_poly.bounds\n",
        "    #width = max_x - x\n",
        "    #height = max_y - y\n",
        "    #bbox = (x, y, width, height)\n",
        "    area = multi_poly.area\n",
        "\n",
        "    annotation = {\n",
        "        'segmentation': segmentations,\n",
        "        'iscrowd': is_crowd,\n",
        "        'image_id': image_id,\n",
        "        'category_id': category_id,\n",
        "        'id': annotation_id,\n",
        "        'bbox': bbox,\n",
        "        'area': area\n",
        "    }\n",
        "\n",
        "    return segmentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJR-1DByIlRc"
      },
      "source": [
        "# format all outputs into a list of dicts compatible with COCO\n",
        "\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "#instances = outputs['instances']\n",
        "#instances.pred_masks_rle = [mask_util.encode(np.asfortranarray(mask)) for mask in instances.pred_masks]\n",
        "#for rle in instances.pred_masks_rle:\n",
        "#    rle['counts'] = rle['counts'].decode('utf-8')\n",
        "#instances.remove('pred_masks')\n",
        "\n",
        "# TO TEST INVERT CONVERSION\n",
        "#instances.pred_masks = np.stack([mask_util.decode(rle) for rle in instances.pred_masks_rle])\n",
        "\n",
        "#Inspired from\n",
        "# https://www.immersivelimit.com/create-coco-annotations-from-scratch\n",
        "\n",
        "detection_res = []\n",
        "is_crowd = 0\n",
        "for k, d in enumerate(skku_test_dataset_dicts):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    outputs = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    bboxes = outputs.pred_boxes\n",
        "    scores = outputs.scores\n",
        "    classes = outputs.pred_classes\n",
        "    masks = outputs.pred_masks\n",
        " \n",
        "    #print(\"Image: \",k,\"has {} masks\".format(masks.shape[0]))\n",
        "\n",
        "    #for i,(bbox, score, class_) in enumerate(zip(bboxes, scores, classes)):\n",
        "    #  #print(i,bbox.tolist(), score.item(), class_.item(), d[\"image_id\"])\n",
        "    #  annotations = []\n",
        "    #  for j, mask in enumerate(masks):\n",
        "    #    #category_id = category_ids[image_id][color]\n",
        "    #    annotation = create_sub_mask_annotation(mask, d[\"image_id\"], class_, j, is_crowd, xyxy2xywh(bbox))\n",
        "    #    annotations.append(annotation)\n",
        "    #  #annotation_id += 1\n",
        "    #  #image_id += 1\n",
        "\n",
        "\n",
        "    for i,(bbox, score, class_, mask) in enumerate(zip(bboxes, scores, classes, masks)):\n",
        "\n",
        "      annotation = create_sub_mask_annotation(mask, d[\"image_id\"], class_, i, is_crowd, xyxy2xywh(bbox))\n",
        "      #annotations.append(annotation)\n",
        "\n",
        "      detection_res.append({\n",
        "          'score': score.item(),\n",
        "          'category_id': class_.item(),\n",
        "          'bbox': xyxy2xywh(bbox),\n",
        "          'image_id': d[\"image_id\"],\n",
        "          'segmentation': annotation\n",
        "      })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHuWIDgMIKbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dd12ec-2f88-4023-8b0d-240762875940"
      },
      "source": [
        "# json file in coco format, original annotation data\n",
        "anno_file = '/content/test/test.json'\n",
        "coco_gt = COCO(anno_file)\n",
        " \n",
        " # Use GT box as prediction box for calculation, the purpose is to get detection_res\n",
        "\n",
        "\"\"\"\n",
        "detection_res = []\n",
        "with open(anno_file, 'r') as f:\n",
        "    json_file = json.load(f)\n",
        "annotations = json_file['annotations']\n",
        "detection_res = []\n",
        "for i, anno in enumerate(annotations):\n",
        "    detection_res.append({\n",
        "        'score': 1,\n",
        "        'category_id': anno['category_id'],\n",
        "        'bbox': anno['bbox'],\n",
        "        'image_id': anno['image_id']\n",
        "    })\n",
        "    if i < 1 :\n",
        "      print( anno['category_id'], anno['image_id'])\n",
        "\"\"\"\n",
        " \n",
        "with NamedTemporaryFile(suffix='.json') as tf:\n",
        "         # Due to subsequent needs, first convert detection_res to binary and then write it to the json file\n",
        "    content = json.dumps(detection_res).encode(encoding='utf-8')\n",
        "    tf.write(content)\n",
        "    res_path = tf.name\n",
        " \n",
        "         # loadRes will generate a new COCO type instance based on coco_gt and return\n",
        "    coco_dt = coco_gt.loadRes(res_path)\n",
        " \n",
        "    cocoEval = COCOeval(coco_gt, coco_dt, 'bbox')  # use 'bbox' for bbox mAP or 'segm' for instance segmentation mAP\n",
        "    cocoEval.evaluate()\n",
        "    cocoEval.accumulate()\n",
        "    cocoEval.summarize()\n",
        " \n",
        "print(cocoEval.stats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.74s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.198\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.099\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
            "[0.14747949 0.1980494  0.17111714 0.04113861 0.12671546 0.17802234\n",
            " 0.0115099  0.0994802  0.15858911 0.04090909 0.13730337 0.18985294]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EC_1aCOWok"
      },
      "source": [
        "#mAP\n",
        "mean_ap = cocoEval.stats[0].item()  # stats[0] records AP@[0.5:0.95]\n",
        "print(\"mAP: \", mean_ap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF9VgUouISMK"
      },
      "source": [
        "print(coco_gt.getAnnIds())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5EMtkDLv1W5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "f9c06df6-bbe3-4efb-c099-867f4c248a94"
      },
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "experiment_folder = './output/'\n",
        "\n",
        "def load_json_arr(json_path):\n",
        "    lines = []\n",
        "    with open(json_path, 'r') as f:\n",
        "        for line in f:\n",
        "            lines.append(json.loads(line))\n",
        "    return lines\n",
        "\n",
        "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Iteration')\n",
        "ax1.set_ylabel('Loss')\n",
        "print(len(experiment_metrics))\n",
        "print(experiment_metrics[0].keys())\n",
        "\n",
        "ax1.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'total_loss' in x], \n",
        "    [x['total_loss'] for x in experiment_metrics if 'total_loss' in x], color=\"black\", label=\"Total Loss\")\n",
        "ax1.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'total_val_loss' in x], \n",
        "    [x['total_val_loss'] for x in experiment_metrics if 'total_val_loss' in x], color=\"red\", label=\"Val Loss\")\n",
        "    \n",
        "ax1.tick_params(axis='y')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "color = 'tab:orange'\n",
        "ax2.set_ylabel('AP')\n",
        "ax2.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
        "    [x['bbox/AP'] for x in experiment_metrics if 'bbox/AP' in x], color=color, label=\"AP\")\n",
        "ax2.tick_params(axis='y')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n",
            "dict_keys(['data_time', 'eta_seconds', 'fast_rcnn/cls_accuracy', 'fast_rcnn/false_negative', 'fast_rcnn/fg_cls_accuracy', 'iteration', 'loss_box_reg', 'loss_cls', 'loss_mask', 'loss_rpn_cls', 'loss_rpn_loc', 'lr', 'mask_rcnn/accuracy', 'mask_rcnn/false_negative', 'mask_rcnn/false_positive', 'roi_head/num_bg_samples', 'roi_head/num_fg_samples', 'rpn/num_neg_anchors', 'rpn/num_pos_anchors', 'time', 'total_loss', 'total_val_loss', 'val_loss_box_reg', 'val_loss_cls', 'val_loss_mask', 'val_loss_rpn_cls', 'val_loss_rpn_loc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-252fe4eb8493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m ax2.plot(\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiment_metrics\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'validation_loss'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     [x['bbox/AP'] for x in experiment_metrics if 'bbox/AP' in x], color=color, label=\"AP\")\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (0,) and (13,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}