{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2_custom_coco_data_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanmed/detectron2_instance_segmentation_demo/blob/master/Detectron2_custom_coco_data_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR"
      },
      "source": [
        "!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "import torch, torchvision\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w0eqA3ECcEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf51fc7d-b425-4760-da91-fc261bf14baf"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the fruits nuts segmentation dataset](https://github.com/Tony607/mmdetection_instance_segmentation_demo)\n",
        "which only has 3 classes: data, fig, and hazelnut.\n",
        "We'll train a segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have the \"data\", \"fig\" and \"hazelnut\" categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPlVyYX164Jp"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWpBjumk66ZZ"
      },
      "source": [
        "#import gdown\n",
        "#import shutil\n",
        "#https://drive.google.com/file/d/14ZcrZ9JbU8_XvCkGvq00xrZt2hioZjGv/view?usp=sharing\n",
        "#url = 'https://drive.google.com/uc?id=14ZcrZ9JbU8_XvCkGvq00xrZt2hioZjGv'\n",
        "#output = 'data.zip'\n",
        "#gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvXceRn17ByN"
      },
      "source": [
        "#!unzip data.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb"
      },
      "source": [
        "# Download test set\n",
        "#https://drive.google.com/file/d/1IZpWoEfXUndLCVs0KWVnJxJuH0klxKUY/view?usp=sharing\n",
        "#url = 'https://drive.google.com/uc?id=1IZpWoEfXUndLCVs0KWVnJxJuH0klxKUY'\n",
        "#output = 'test.zip'\n",
        "#gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9_ls08j8RbV"
      },
      "source": [
        "#!unzip test.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6p8Rlh3ktoX"
      },
      "source": [
        "# Download full dataset\n",
        "import gdown\n",
        "import shutil\n",
        "# smaller dataset: https://drive.google.com/file/d/1kix_r_P3YWa_3bI9JpBJ2hKzHF8WjA53/view?usp=sharing\n",
        "# full dataset https://drive.google.com/file/d/1CKo1ls81LEOBM-HDuauOT1_Tb1f3Bh2W/view?usp=sharing\n",
        "url = 'https://drive.google.com/uc?id=1kix_r_P3YWa_3bI9JpBJ2hKzHF8WjA53'\n",
        "output = 'dataset.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl7mXwhgZDUC"
      },
      "source": [
        "#Download person_keypoints_val2017 COCO annotations and images\n",
        "# https://drive.google.com/file/d/12EcuLb9QP1TYz5ozQprQwIFJmKPMGyCe/view?usp=sharing\n",
        "url = 'https://drive.google.com/uc?id=12EcuLb9QP1TYz5ozQprQwIFJmKPMGyCe'\n",
        "output = 'person_keypoints_val2017.json'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v764biXLdffg"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKoqD694doH9"
      },
      "source": [
        "!unzip val2017.zip -d ./person_keypoints2017_val/ > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcZOHG3KlIQx"
      },
      "source": [
        "!unzip dataset.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS6RNGRNj83n"
      },
      "source": [
        "!rm dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTut7JjhmXAH"
      },
      "source": [
        "#download latest model\n",
        "#ttps://drive.google.com/file/d/1lhBxaXSDzc8HaJFtXfLb9qcmS3VDyDnK/view?usp=sharing\n",
        "url = \"https://drive.google.com/uc?id=1lhBxaXSDzc8HaJFtXfLb9qcmS3VDyDnK\"\n",
        "output = 'model_final.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZexjDocemoBn"
      },
      "source": [
        "!mv model_final.pth output/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6EIA_WhjTPw"
      },
      "source": [
        "# Add keypoints to json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0EIY7Exjb_H",
        "outputId": "2c35149c-b5eb-40ed-d86a-8da28d97302b"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "import requests\n",
        "\n",
        " \n",
        "raw_dir = \"./\"\n",
        "splits = [\"val\",\"test\",\"train\"]\n",
        "label_dir = 'test/test.json'\n",
        "\n",
        "for split in splits:\n",
        "  with open(os.path.join(raw_dir,split,split+\".json\"),'r') as coco_file:\n",
        "    coco_labels = json.load(coco_file)\n",
        "\n",
        "  anns = coco_labels['annotations']\n",
        "  for ann in anns:\n",
        "    bbox = ann['bbox']\n",
        "    ann['keypoints'] = [bbox[0]+bbox[2]//2,bbox[1]+bbox[3]//2,2]\n",
        "    ann['num_keypoints'] = 1\n",
        "  \n",
        "  with open(os.path.join(raw_dir,split,split+\"2.json\"), 'w') as file:\n",
        "      json.dump(data, file)\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "# load dataset\n",
        "#coco_anns = COCO(label_dir)\n",
        "# get categories and print\n",
        "#cats = coco_anns.loadCats(coco_anns.getCatIds())\n",
        "# get all images containing given categories, select one at random\n",
        "#catIds = coco_anns.getCatIds(catNms=['box','sack','pouch','icebox']);\n",
        "#imgIds = coco_anns.getImgIds(catIds=catIds);\n",
        "#img_data = coco_anns.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
        "# select one annotation, read image and draw image with annotation\n",
        "#annIds = coco_anns.getAnnIds(imgIds = img_data['id'], catIds=catIds, iscrowd=None)\n",
        "#anns = coco_anns.loadAnns(annIds)\n",
        "#img_path = os.path.join(raw_dir,split,img_data['file_name'])\n",
        "#img = io.imread(img_path)\n",
        "#fig = plt.figure()\n",
        "#ax1 = fig.add_subplot(1,1,1)\n",
        "#ax1.imshow(img)\n",
        "#coco_anns.showAnns(anns)\n",
        "#plt.show()\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['images', 'categories', 'annotations', 'info', 'licenses'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW"
      },
      "source": [
        "# Register the fruits_nuts dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnkg1PByUjGQ"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"skku_unloading_coco_train\", {}, \"./train/train.json\", \"./train/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWknKqWTWIw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23637dbb-3f40-4d82-8ec7-337ef40b9cb5"
      },
      "source": [
        "skku_train_metadata = MetadataCatalog.get(\"skku_unloading_coco_train\")\n",
        "skku_train_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_train\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/05 06:24:44 d2.data.datasets.coco]: \u001b[0mLoaded 300 images in COCO format from ./train/train.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--YvOJEP7q32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bfd5e5e-0584-4c12-f622-3257df030b62"
      },
      "source": [
        "register_coco_instances(\"skku_unloading_coco_test\", {}, \"./test/test.json\", \"./test/\")\n",
        "skku_test_metadata = MetadataCatalog.get(\"skku_unloading_coco_test\")\n",
        "skku_test_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/05 06:24:47 d2.data.datasets.coco]: \u001b[0mLoaded 52 images in COCO format from ./test/test.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD59X3RufXms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0f6da8-68b1-4e3e-d3aa-36f3bbb62911"
      },
      "source": [
        "register_coco_instances(\"skku_unloading_coco_val\", {}, \"./val/val.json\", \"./val/\")\n",
        "skku_val_metadata = MetadataCatalog.get(\"skku_unloading_coco_val\")\n",
        "skku_val_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_val\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/05 06:24:48 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4tozgiOR30g",
        "outputId": "02edce66-c4a5-4441-89df-0953ef3c6c70"
      },
      "source": [
        "register_coco_instances(\"person_keypoints\", {}, \"./person_keypoints_val2017.json\", \"./person_keypoints2017_val/val2017/\")\n",
        "pk_val_metadata = MetadataCatalog.get(\"person_keypoints\")\n",
        "pk_val_dataset_dicts = DatasetCatalog.get(\"person_keypoints\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/05 06:24:51 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from ./person_keypoints_val2017.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn7xnoIbJp-C",
        "outputId": "630b5adc-799d-47ab-9f23-f6d55d103b49"
      },
      "source": [
        "print(pk_val_metadata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metadata(evaluator_type='coco', image_root='./person_keypoints2017_val/val2017/', json_file='./person_keypoints_val2017.json', name='person_keypoints', thing_classes=['person'], thing_dataset_id_to_contiguous_id={1: 0})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTVdacOsuqAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc91fa27-fc24-4998-bf25-13eb8d34afaa"
      },
      "source": [
        "print((pk_val_dataset_dicts[0]['annotations'][0]['bbox_mode']))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BoxMode.XYWH_ABS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCtGLrbpuqgM"
      },
      "source": [
        "## Keypoint Integration\n",
        "Add the ***keypoints*** key to each annotation, as well as the *keypoint_names* and *keypoints_flip_map* to the metadata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ5y-EM6dR-f"
      },
      "source": [
        "import random\n",
        "for ele in skku_train_dataset_dicts:\n",
        "  anns = ele['annotations']\n",
        "  for ann in anns:\n",
        "    ann['keypoints'] = [12.3,11.4,2]\n",
        "    ann['num_keypoints'] = 1\n",
        "for ele in skku_test_dataset_dicts:\n",
        "  anns = ele['annotations']\n",
        "  for ann in anns:\n",
        "    ann['keypoints'] = [12.3,11.4,2]\n",
        "    ann['num_keypoints'] = 1\n",
        "for ele in skku_val_dataset_dicts:\n",
        "  anns = ele['annotations']\n",
        "  for ann in anns:\n",
        "    ann['keypoints'] = [12.3,11.4,2]\n",
        "    ann['num_keypoints'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkwaeM_8GAQT"
      },
      "source": [
        "print((skku_val_dataset_dicts[0]['annotations'][0].keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqnCbD5DpaZm"
      },
      "source": [
        "skku_test_metadata.keypoint_names = ['grasp']\n",
        "skku_train_metadata.keypoint_names = ['grasp']\n",
        "skku_val_metadata.keypoint_names = ['grasp']\n",
        "\n",
        "skku_test_metadata.keypoint_flip_map = []\n",
        "skku_train_metadata.keypoint_flip_map = []\n",
        "skku_val_metadata.keypoint_flip_map = []\n",
        "\n",
        "pk_val_metadata.keypoint_names = [\"nose\",\"left_eye\", \"right_eye\",\n",
        "        \"left_ear\",\n",
        "        \"right_ear\",\n",
        "        \"left_shoulder\",\n",
        "        \"right_shoulder\",\n",
        "        \"left_elbow\",\n",
        "        \"right_elbow\",\n",
        "        \"left_wrist\",\n",
        "        \"right_wrist\",\n",
        "        \"left_hip\",\n",
        "        \"right_hip\",\n",
        "        \"left_knee\",\n",
        "        \"right_knee\",\n",
        "        \"left_ankle\",\n",
        "        \"right_ankle\"\n",
        "      ]\n",
        "pk_val_metadata.keypoint_flip_map = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHjohciLkSN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1595491b-74eb-478e-c38e-584744cbe282"
      },
      "source": [
        "len(pk_val_metadata.keypoint_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq016mKhQvcu"
      },
      "source": [
        "annos = pk_val_dataset_dicts[0]['annotations']\n",
        "from detectron2.structures import (\n",
        "    BitMasks,\n",
        "    Boxes,\n",
        "    BoxMode,\n",
        "    Instances,\n",
        "    Keypoints,\n",
        "    PolygonMasks,\n",
        "    RotatedBoxes,\n",
        "    polygons_to_bitmask,\n",
        ")\n",
        "if len(annos) and \"keypoints\" in annos[0]:\n",
        "  kpts = [obj.get(\"keypoints\", []) for obj in annos]\n",
        "  target.gt_keypoints = Keypoints(kpts)\n",
        "print(kpts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBRfiwZGJB93"
      },
      "source": [
        "from detectron2.data.detection_utils import annotations_to_instances\n",
        "\n",
        "inst = annotations_to_instances(skku_val_dataset_dicts[0]['annotations'], image_size=(1536,2048))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkNbUzUOLYf0"
      },
      "source": [
        "import random\n",
        "\n",
        "for d in random.sample(skku_train_dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=skku_train_metadata, scale=0.35)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6jKzZdFfdNX"
      },
      "source": [
        "for d in random.sample(pk_val_dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=pk_val_metadata, scale=0.35)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the fruits_nuts dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2p1U5OneZet"
      },
      "source": [
        "#Prepare tensorboard\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxczkMPwZ7zE"
      },
      "source": [
        "\n",
        "LOG_DIR = '/content/output/'\n",
        "print(LOG_DIR)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUoCbV9gD-G3"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tuGzjukEzwl"
      },
      "source": [
        "!rm -rf output/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feWHOrX5jo10"
      },
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "# Evaluation code from\n",
        "#https://github.com/facebookresearch/detectron2/issues/810#issuecomment-596194293\n",
        "\n",
        "# More detailed implementation at\n",
        "#https://medium.com/@apofeniaco/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
        "##or\n",
        "#https://tshafer.com/blog/2020/06/detectron2-eval-loss\n",
        "\n",
        "from detectron2.engine import HookBase\n",
        "from detectron2.data import build_detection_train_loader\n",
        "import detectron2.utils.comm as comm\n",
        "import torch\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "    if output_folder is None:\n",
        "      output_folder = os.path.join(cfg.OUTPUT_DIR,\"inference\")\n",
        "    return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "\n",
        "class ValidationLoss(HookBase):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg.clone()\n",
        "        self.cfg.DATASETS.TRAIN = cfg.DATASETS.VAL\n",
        "        self._loader = iter(build_detection_train_loader(self.cfg))\n",
        "        \n",
        "    def after_step(self):\n",
        "        data = next(self._loader)\n",
        "        with torch.no_grad():\n",
        "            loss_dict = self.trainer.model(data)\n",
        "            \n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in \n",
        "                                 comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                self.trainer.storage.put_scalars(total_val_loss=losses_reduced, \n",
        "                                                 **loss_dict_reduced)\n",
        "\n",
        "cfg = get_cfg()\n",
        "#cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\") # for instance segmentation\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"person_keypoints\",)\n",
        "cfg.DATASETS.TEST = (\"person_keypoints\",)   # no metrics implemented for this dataset\n",
        "#cfg.DATASETS.VAL = (\"skku_unloading_coco_val\",)   # no metrics implemented for this dataset\n",
        "cfg.TEST.EVAL_PERIOD = 0\n",
        "#cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")  # initialize from model zoo\n",
        "#cfg.MODEL.WEIGHTS = detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "\n",
        "# ********* Learning rate calc: https://github.com/facebookresearch/detectron2/issues/1128#issuecomment-774175041\n",
        "num_gpu = 1\n",
        "bs = (num_gpu * 2)\n",
        "cfg.SOLVER.BASE_LR = 0.01 * bs / 32  # pick a good LR\n",
        "# ********\n",
        "cfg.SOLVER.MAX_ITER = 300   # 300 iterations seems good enough, but you can certainly train longer\n",
        "#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset\n",
        "#cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # 4 classes (box, icebox, pouch, sack)\n",
        "\n",
        "#   ENABLE KEYPOINT REGRESSION\n",
        "#cfg.MODEL.KEYPOINT_ON = True\n",
        "#cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 17\n",
        "#cfg.MODEL.ROI_KEYPOINT_HEAD.MIN_KEYPOINTS_PER_IMAGE = 0\n",
        "#cfg.TEST.KEYPOINT_OKS_SIGMAS = 1\n",
        "\n",
        "#   ENABLE INSTANCE SEGMENTATION\n",
        "#cfg.MODEL.MASK_ON =  True\n",
        "#cfg.MODEL.SEM_SEG_HEAD.LOSS_WEIGHT = 1.0\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) #MyTrainer(cfg) #\n",
        "#val_loss = ValidationLoss(cfg)  \n",
        "#trainer.register_hooks([val_loss])\n",
        "# swap the order of PeriodicWriter and ValidationLoss\n",
        "#trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]\n",
        "#trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URYJStnUCTOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d9baeb-5ee5-4ad3-9af9-56e5157747e0"
      },
      "source": [
        "print(cfg.MODEL.SEM_SEG_HEAD.LOSS_WEIGHT)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJHRlEm_FMhO"
      },
      "source": [
        "!zip -r output.zip output\n",
        "from google.colab import files\n",
        "files.download('output.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvC61lS9VptR"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set the testing threshold for this model\n",
        "#cfg.DATASETS.TEST = (\"skku_unloading_coco_test\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfLx83yVaOEP"
      },
      "source": [
        "Do evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKjmc5-aaNJS"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"skku_unloading_coco_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"skku_unloading_coco_test\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import random\n",
        "\n",
        "for d in random.sample(pk_val_dataset_dicts, 5):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=pk_val_metadata, \n",
        "                   scale=0.4, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bo0cypwllj"
      },
      "source": [
        "skku_train_metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6lYrCqLLLW"
      },
      "source": [
        "## Benchmark inference speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxRHYcAC_Z0f"
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vm2paQxDUMn"
      },
      "source": [
        "# Evaluate performance using pyCOCOtools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFMOqBbWEh5v"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go3Y1NuoDr2d"
      },
      "source": [
        "from pycocotools.coco import COCO \n",
        "from pycocotools.cocoeval import COCOeval \n",
        "import numpy as np \n",
        "import skimage.io as io \n",
        "import pylab,json \n",
        "from tempfile import NamedTemporaryFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtr1AwIRLxLr"
      },
      "source": [
        "def xyxy2xywh(bbox):\n",
        "        \"\"\"Convert ``xyxy`` style bounding boxes to ``xywh`` style for COCO\n",
        "        evaluation.\n",
        "\n",
        "        Args:\n",
        "            bbox (numpy.ndarray): The bounding boxes, shape (4, ), in\n",
        "                ``xyxy`` order.\n",
        "\n",
        "        Returns:\n",
        "            list[float]: The converted bounding boxes, in ``xywh`` order.\n",
        "        \"\"\"\n",
        "\n",
        "        _bbox = bbox.tolist()\n",
        "        return [\n",
        "            _bbox[0],\n",
        "            _bbox[1],\n",
        "            _bbox[2] - _bbox[0],\n",
        "            _bbox[3] - _bbox[1],\n",
        "        ] \n",
        "\n",
        "import numpy as np                                 # (pip install numpy)\n",
        "from skimage import measure                        # (pip install scikit-image)\n",
        "from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n",
        "\n",
        "def create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd, bbox):\n",
        "    # Find contours (boundary lines) around each sub-mask\n",
        "    # Note: there could be multiple contours if the object\n",
        "    # is partially occluded. (E.g. an elephant behind a tree)\n",
        "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
        "\n",
        "    segmentations = []\n",
        "    polygons = []\n",
        "    #print(len(contours))\n",
        "    for contour in contours:\n",
        "        # Flip from (row, col) representation to (x, y)\n",
        "        # and subtract the padding pixel\n",
        "        for i in range(len(contour)):\n",
        "            row, col = contour[i]\n",
        "            contour[i] = (col - 1, row - 1)\n",
        "\n",
        "        # Make a polygon and simplify it\n",
        "        poly = Polygon(contour)\n",
        "        poly = poly.simplify(1.0, preserve_topology=False)\n",
        "        polygons.append(poly)\n",
        "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
        "        if len(segmentation) > 4:\n",
        "          segmentations.append(segmentation)\n",
        "\n",
        "    # Combine the polygons to calculate the bounding box and area\n",
        "    multi_poly = MultiPolygon(polygons)\n",
        "    #x, y, max_x, max_y = multi_poly.bounds\n",
        "    #width = max_x - x\n",
        "    #height = max_y - y\n",
        "    #bbox = (x, y, width, height)\n",
        "    area = multi_poly.area\n",
        "\n",
        "    annotation = {\n",
        "        'segmentation': segmentations,\n",
        "        'iscrowd': is_crowd,\n",
        "        'image_id': image_id,\n",
        "        'category_id': category_id,\n",
        "        'id': annotation_id,\n",
        "        'bbox': bbox,\n",
        "        'area': area\n",
        "    }\n",
        "\n",
        "    return segmentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJR-1DByIlRc"
      },
      "source": [
        "# format all outputs into a list of dicts compatible with COCO\n",
        "\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "#instances = outputs['instances']\n",
        "#instances.pred_masks_rle = [mask_util.encode(np.asfortranarray(mask)) for mask in instances.pred_masks]\n",
        "#for rle in instances.pred_masks_rle:\n",
        "#    rle['counts'] = rle['counts'].decode('utf-8')\n",
        "#instances.remove('pred_masks')\n",
        "\n",
        "# TO TEST INVERT CONVERSION\n",
        "#instances.pred_masks = np.stack([mask_util.decode(rle) for rle in instances.pred_masks_rle])\n",
        "\n",
        "#Inspired from\n",
        "# https://www.immersivelimit.com/create-coco-annotations-from-scratch\n",
        "\n",
        "detection_res = []\n",
        "is_crowd = 0\n",
        "for k, d in enumerate(skku_test_dataset_dicts):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    outputs = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    bboxes = outputs.pred_boxes\n",
        "    scores = outputs.scores\n",
        "    classes = outputs.pred_classes\n",
        "    masks = outputs.pred_masks\n",
        " \n",
        "    #print(\"Image: \",k,\"has {} masks\".format(masks.shape[0]))\n",
        "\n",
        "    #for i,(bbox, score, class_) in enumerate(zip(bboxes, scores, classes)):\n",
        "    #  #print(i,bbox.tolist(), score.item(), class_.item(), d[\"image_id\"])\n",
        "    #  annotations = []\n",
        "    #  for j, mask in enumerate(masks):\n",
        "    #    #category_id = category_ids[image_id][color]\n",
        "    #    annotation = create_sub_mask_annotation(mask, d[\"image_id\"], class_, j, is_crowd, xyxy2xywh(bbox))\n",
        "    #    annotations.append(annotation)\n",
        "    #  #annotation_id += 1\n",
        "    #  #image_id += 1\n",
        "\n",
        "\n",
        "    for i,(bbox, score, class_, mask) in enumerate(zip(bboxes, scores, classes, masks)):\n",
        "\n",
        "      annotation = create_sub_mask_annotation(mask, d[\"image_id\"], class_, i, is_crowd, xyxy2xywh(bbox))\n",
        "      #annotations.append(annotation)\n",
        "\n",
        "      detection_res.append({\n",
        "          'score': score.item(),\n",
        "          'category_id': class_.item(),\n",
        "          'bbox': xyxy2xywh(bbox),\n",
        "          'image_id': d[\"image_id\"],\n",
        "          'segmentation': annotation\n",
        "      })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHuWIDgMIKbF"
      },
      "source": [
        "# json file in coco format, original annotation data\n",
        "anno_file = '/content/test/test.json'\n",
        "coco_gt = COCO(anno_file)\n",
        " \n",
        " # Use GT box as prediction box for calculation, the purpose is to get detection_res\n",
        "\n",
        "\"\"\"\n",
        "detection_res = []\n",
        "with open(anno_file, 'r') as f:\n",
        "    json_file = json.load(f)\n",
        "annotations = json_file['annotations']\n",
        "detection_res = []\n",
        "for i, anno in enumerate(annotations):\n",
        "    detection_res.append({\n",
        "        'score': 1,\n",
        "        'category_id': anno['category_id'],\n",
        "        'bbox': anno['bbox'],\n",
        "        'image_id': anno['image_id']\n",
        "    })\n",
        "    if i < 1 :\n",
        "      print( anno['category_id'], anno['image_id'])\n",
        "\"\"\"\n",
        " \n",
        "with NamedTemporaryFile(suffix='.json') as tf:\n",
        "         # Due to subsequent needs, first convert detection_res to binary and then write it to the json file\n",
        "    content = json.dumps(detection_res).encode(encoding='utf-8')\n",
        "    tf.write(content)\n",
        "    res_path = tf.name\n",
        " \n",
        "         # loadRes will generate a new COCO type instance based on coco_gt and return\n",
        "    coco_dt = coco_gt.loadRes(res_path)\n",
        " \n",
        "    cocoEval = COCOeval(coco_gt, coco_dt, 'bbox')  # use 'bbox' for bbox mAP or 'segm' for instance segmentation mAP\n",
        "    cocoEval.evaluate()\n",
        "    cocoEval.accumulate()\n",
        "    cocoEval.summarize()\n",
        " \n",
        "print(cocoEval.stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EC_1aCOWok"
      },
      "source": [
        "#mAP\n",
        "mean_ap = cocoEval.stats[0].item()  # stats[0] records AP@[0.5:0.95]\n",
        "print(\"mAP: \", mean_ap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF9VgUouISMK"
      },
      "source": [
        "print(coco_gt.getAnnIds())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5EMtkDLv1W5"
      },
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "experiment_folder = './output/'\n",
        "\n",
        "def load_json_arr(json_path):\n",
        "    lines = []\n",
        "    with open(json_path, 'r') as f:\n",
        "        for line in f:\n",
        "            lines.append(json.loads(line))\n",
        "    return lines\n",
        "\n",
        "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Iteration')\n",
        "ax1.set_ylabel('Loss')\n",
        "print(len(experiment_metrics))\n",
        "print(experiment_metrics[0].keys())\n",
        "\n",
        "ax1.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'total_loss' in x], \n",
        "    [x['total_loss'] for x in experiment_metrics if 'total_loss' in x], color=\"black\", label=\"Total Loss\")\n",
        "ax1.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'total_val_loss' in x], \n",
        "    [x['total_val_loss'] for x in experiment_metrics if 'total_val_loss' in x], color=\"red\", label=\"Val Loss\")\n",
        "    \n",
        "ax1.tick_params(axis='y')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "color = 'tab:orange'\n",
        "ax2.set_ylabel('AP')\n",
        "ax2.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
        "    [x['bbox/AP'] for x in experiment_metrics if 'bbox/AP' in x], color=color, label=\"AP\")\n",
        "ax2.tick_params(axis='y')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}