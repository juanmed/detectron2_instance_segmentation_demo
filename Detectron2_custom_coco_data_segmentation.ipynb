{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2_custom_coco_data_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanmed/detectron2_instance_segmentation_demo/blob/master/Detectron2_custom_coco_data_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UPaAdWoVgJx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# [How to train Detectron2 with Custom COCO Datasets](https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/) | DLology\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "This notebook will help you get started with this framwork by training a instance segmentation model with your custom COCO datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "0f29ea8a-da39-4ca3-c184-bcd77b804e72"
      },
      "source": [
        "!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "import torch, torchvision\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already up-to-date: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-wsdi33pe\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-wsdi33pe\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.19.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (4.41.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (0.8.9)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/21/d0/22104caed16fa41382702fed959f4a9b088b2f905e7a82e4483180a2ec2a/iopath-0.1.8-py3-none-any.whl\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5-cp37-none-any.whl size=62712 sha256=e84633205ef16bfeecff60223d21a1083b3aaa9ad04a612d5154b16bf82bb1e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d9js5p1a/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n",
            "Successfully built fvcore\n",
            "Installing collected packages: pyyaml, yacs, portalocker, iopath, fvcore\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed fvcore-0.1.5 iopath-0.1.8 portalocker-2.3.0 pyyaml-5.4.1 yacs-0.1.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.1+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c65e4e27-1ab6-41df-ca27-25821d157a4b"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'detectron2_repo'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Counting objects: 100% (210/210), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 11469 (delta 77), reused 140 (delta 63), pack-reused 11259\u001b[K\n",
            "Receiving objects: 100% (11469/11469), 4.68 MiB | 10.48 MiB/s, done.\n",
            "Resolving deltas: 100% (8296/8296), done.\n",
            "Obtaining file:///content/detectron2_repo\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (1.1.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (7.1.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (0.8.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (3.2.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (4.41.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (2.4.1)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (0.1.5)\n",
            "Collecting iopath<0.1.8,>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/d5/1c70fea7632640e8a9fb5a176676e555238119b3e7ee8b6dc49980ec5769/iopath-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (2.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (1.3.0)\n",
            "Collecting omegaconf==2.1.0.dev22\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/1c/6ecce6df0e112f381c355144b4f8de56157e68abbf93a7dd3fbf98d28ac2/omegaconf-2.1.0.dev22-py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs>=0.1.6->detectron2==0.4) (5.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (2.4.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (54.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (3.12.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (0.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.28.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.8,>=0.1.7->detectron2==0.4) (2.3.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2==0.4) (0.29.22)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.4) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.4) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.4) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.4.8)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=01c875ffa9a82205bdd4bd371ba98074672f05d3aa2fa4c18cc62ea3b0b9ccf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: iopath, antlr4-python3-runtime, omegaconf, detectron2\n",
            "  Found existing installation: iopath 0.1.8\n",
            "    Uninstalling iopath-0.1.8:\n",
            "      Successfully uninstalled iopath-0.1.8\n",
            "  Running setup.py develop for detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.8 detectron2 iopath-0.1.7 omegaconf-2.1.0.dev22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w0eqA3ECcEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a50a35a-c835-42e6-e8fc-54befa9e889b"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the fruits nuts segmentation dataset](https://github.com/Tony607/mmdetection_instance_segmentation_demo)\n",
        "which only has 3 classes: data, fig, and hazelnut.\n",
        "We'll train a segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have the \"data\", \"fig\" and \"hazelnut\" categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPlVyYX164Jp",
        "outputId": "4ce406d3-84b1-43ca-fbcd-4c3ded8bc396"
      },
      "source": [
        "!pip install gdown"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWpBjumk66ZZ"
      },
      "source": [
        "#import gdown\n",
        "#import shutil\n",
        "#https://drive.google.com/file/d/14ZcrZ9JbU8_XvCkGvq00xrZt2hioZjGv/view?usp=sharing\n",
        "#url = 'https://drive.google.com/uc?id=14ZcrZ9JbU8_XvCkGvq00xrZt2hioZjGv'\n",
        "#output = 'data.zip'\n",
        "#gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvXceRn17ByN"
      },
      "source": [
        "#!unzip data.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb"
      },
      "source": [
        "# Download test set\n",
        "#https://drive.google.com/file/d/1IZpWoEfXUndLCVs0KWVnJxJuH0klxKUY/view?usp=sharing\n",
        "#url = 'https://drive.google.com/uc?id=1IZpWoEfXUndLCVs0KWVnJxJuH0klxKUY'\n",
        "#output = 'test.zip'\n",
        "#gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9_ls08j8RbV"
      },
      "source": [
        "#!unzip test.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6p8Rlh3ktoX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "046d4567-f6be-402b-e83c-181d43f34060"
      },
      "source": [
        "# Download full dataset\n",
        "import gdown\n",
        "import shutil\n",
        "#https://drive.google.com/file/d/1CKo1ls81LEOBM-HDuauOT1_Tb1f3Bh2W/view?usp=sharing\n",
        "url = 'https://drive.google.com/uc?id=1CKo1ls81LEOBM-HDuauOT1_Tb1f3Bh2W'\n",
        "output = 'dataset.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CKo1ls81LEOBM-HDuauOT1_Tb1f3Bh2W\n",
            "To: /content/dataset.zip\n",
            "7.25GB [02:30, 48.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dataset.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcZOHG3KlIQx"
      },
      "source": [
        "!unzip dataset.zip > /dev/null"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS6RNGRNj83n"
      },
      "source": [
        "!rm dataset.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW"
      },
      "source": [
        "Register the fruits_nuts dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnkg1PByUjGQ"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"skku_unloading_coco_train\", {}, \"./train/train.json\", \"./train/\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWknKqWTWIw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ccd9f1-4174-40dc-cad0-a081b0e5ac7d"
      },
      "source": [
        "skku_train_metadata = MetadataCatalog.get(\"skku_unloading_coco_train\")\n",
        "skku_train_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_train\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/01 11:29:03 d2.data.datasets.coco]: \u001b[0mLoading ./train/train.json takes 2.81 seconds.\n",
            "\u001b[32m[04/01 11:29:03 d2.data.datasets.coco]: \u001b[0mLoaded 900 images in COCO format from ./train/train.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 11:29:04 d2.data.datasets.coco]: \u001b[0mFiltered out 5 instances without valid segmentation. There might be issues in your dataset generation process. A valid polygon should be a list[float] with even length >= 6.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--YvOJEP7q32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6620e39-0dbf-4f96-cead-61bf989adbe8"
      },
      "source": [
        "register_coco_instances(\"skku_unloading_coco_test\", {}, \"./test/test.json\", \"./test/\")\n",
        "skku_test_metadata = MetadataCatalog.get(\"skku_unloading_coco_test\")\n",
        "skku_test_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_test\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/01 11:29:04 d2.data.datasets.coco]: \u001b[0mLoaded 52 images in COCO format from ./test/test.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD59X3RufXms",
        "outputId": "b7f58db9-4cc5-4d49-a343-b0e441ad2a7c"
      },
      "source": [
        "register_coco_instances(\"skku_unloading_coco_val\", {}, \"./val/val.json\", \"./val/\")\n",
        "skku_val_metadata = MetadataCatalog.get(\"skku_unloading_coco_val\")\n",
        "skku_val_dataset_dicts = DatasetCatalog.get(\"skku_unloading_coco_val\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/01 11:29:04 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkNbUzUOLYf0"
      },
      "source": [
        "import random\n",
        "\n",
        "for d in random.sample(skku_train_dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=skku_train_metadata, scale=0.35)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the fruits_nuts dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2p1U5OneZet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e569bbe3-9d92-44b2-c7d7-cfbb30104ed6"
      },
      "source": [
        "#Prepare tensorboard\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-01 11:29:04--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.203.100.2, 34.195.37.70, 3.226.107.193, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.203.100.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14746350 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.06M  7.02MB/s    in 2.0s    \n",
            "\n",
            "2021-04-01 11:29:07 (7.02 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14746350/14746350]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxczkMPwZ7zE",
        "outputId": "43375828-28ca-42cb-989f-26bd9a873df6"
      },
      "source": [
        "\n",
        "LOG_DIR = '/content/output/'\n",
        "print(LOG_DIR)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/output/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUoCbV9gD-G3",
        "outputId": "b52850b5-052e-466c-8c5a-ebe4e86911c3"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tuGzjukEzwl"
      },
      "source": [
        "!rm -rf output/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be0c4ed-0dad-420a-b880-d002e7cf1947"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "# Evaluation code from\n",
        "#https://github.com/facebookresearch/detectron2/issues/810#issuecomment-596194293\n",
        "\n",
        "# More detailed implementation at\n",
        "#https://medium.com/@apofeniaco/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
        "##or\n",
        "#https://tshafer.com/blog/2020/06/detectron2-eval-loss\n",
        "\n",
        "from detectron2.engine import HookBase\n",
        "from detectron2.data import build_detection_train_loader\n",
        "import detectron2.utils.comm as comm\n",
        "import torch\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "    if output_folder is None:\n",
        "      output_folder = os.path.join(cfg.OUTPUT_DIR,\"inference\")\n",
        "    return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "\n",
        "class ValidationLoss(HookBase):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg.clone()\n",
        "        self.cfg.DATASETS.TRAIN = cfg.DATASETS.VAL\n",
        "        self._loader = iter(build_detection_train_loader(self.cfg))\n",
        "        \n",
        "    def after_step(self):\n",
        "        data = next(self._loader)\n",
        "        with torch.no_grad():\n",
        "            loss_dict = self.trainer.model(data)\n",
        "            \n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in \n",
        "                                 comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                self.trainer.storage.put_scalars(total_val_loss=losses_reduced, \n",
        "                                                 **loss_dict_reduced)\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"skku_unloading_coco_train\",)\n",
        "cfg.DATASETS.TEST = (\"skku_unloading_coco_val\",)   # no metrics implemented for this dataset\n",
        "cfg.DATASETS.VAL = (\"skku_unloading_coco_val\",)   # no metrics implemented for this dataset\n",
        "cfg.TEST.EVAL_PERIOD = 200\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MAX_ITER = 3000   # 300 iterations seems good enough, but you can certainly train longer\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # 3 classes (data, fig, hazelnut)\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg) #DefaultTrainer(cfg)\n",
        "val_loss = ValidationLoss(cfg)  \n",
        "trainer.register_hooks([val_loss])\n",
        "# swap the order of PeriodicWriter and ValidationLoss\n",
        "trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/01 11:29:25 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/01 11:29:29 d2.data.datasets.coco]: \u001b[0mLoading ./train/train.json takes 3.94 seconds.\n",
            "\u001b[32m[04/01 11:29:29 d2.data.datasets.coco]: \u001b[0mLoaded 900 images in COCO format from ./train/train.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 11:29:29 d2.data.datasets.coco]: \u001b[0mFiltered out 5 instances without valid segmentation. There might be issues in your dataset generation process. A valid polygon should be a list[float] with even length >= 6.\n",
            "\u001b[32m[04/01 11:29:29 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 900 images left.\n",
            "\u001b[32m[04/01 11:29:29 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|    sack    | 5459         |   pouch    | 7271         |    box     | 18248        |\n",
            "|   icebox   | 3381         |            |              |            |              |\n",
            "|   total    | 34359        |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[04/01 11:29:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[04/01 11:29:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[04/01 11:29:29 d2.data.common]: \u001b[0mSerializing 900 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 11:29:29 d2.data.common]: \u001b[0mSerialized dataset takes 55.99 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 11:29:30 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "\u001b[32m[04/01 11:29:38 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n",
            "\u001b[32m[04/01 11:29:38 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 34 images left.\n",
            "\u001b[32m[04/01 11:29:38 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|    sack    | 160          |   pouch    | 320          |    box     | 572          |\n",
            "|   icebox   | 107          |            |              |            |              |\n",
            "|   total    | 1159         |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[04/01 11:29:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[04/01 11:29:38 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[04/01 11:29:38 d2.data.common]: \u001b[0mSerializing 34 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 11:29:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_f10217.pkl: 178MB [00:31, 5.70MB/s]                           \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/01 11:30:09 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[04/01 11:33:27 d2.utils.events]: \u001b[0m eta: 5:05:48  iter: 19  total_loss: 3.223  loss_cls: 1.26  loss_box_reg: 0.7472  loss_mask: 0.6856  loss_rpn_cls: 0.314  loss_rpn_loc: 0.2405  total_val_loss: 3.172  val_loss_cls: 1.199  val_loss_box_reg: 0.7432  val_loss_mask: 0.6827  val_loss_rpn_cls: 0.2802  val_loss_rpn_loc: 0.2216  time: 6.5751  data_time: 1.9355  lr: 0.00039962  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:36:44 d2.utils.events]: \u001b[0m eta: 5:30:59  iter: 39  total_loss: 2.567  loss_cls: 0.8138  loss_box_reg: 0.7559  loss_mask: 0.5909  loss_rpn_cls: 0.1515  loss_rpn_loc: 0.2303  total_val_loss: 2.48  val_loss_cls: 0.8001  val_loss_box_reg: 0.7539  val_loss_mask: 0.5777  val_loss_rpn_cls: 0.148  val_loss_rpn_loc: 0.2164  time: 6.7492  data_time: 1.8408  lr: 0.00079922  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:39:56 d2.utils.events]: \u001b[0m eta: 5:35:57  iter: 59  total_loss: 2.262  loss_cls: 0.7145  loss_box_reg: 0.7366  loss_mask: 0.4236  loss_rpn_cls: 0.121  loss_rpn_loc: 0.2392  total_val_loss: 2.16  val_loss_cls: 0.6955  val_loss_box_reg: 0.7425  val_loss_mask: 0.3902  val_loss_rpn_cls: 0.1205  val_loss_rpn_loc: 0.1945  time: 6.7043  data_time: 1.9536  lr: 0.0011988  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:43:06 d2.utils.events]: \u001b[0m eta: 5:21:32  iter: 79  total_loss: 2.021  loss_cls: 0.6424  loss_box_reg: 0.7302  loss_mask: 0.3286  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2165  total_val_loss: 1.976  val_loss_cls: 0.6247  val_loss_box_reg: 0.7196  val_loss_mask: 0.3216  val_loss_rpn_cls: 0.0972  val_loss_rpn_loc: 0.1854  time: 6.6491  data_time: 1.6947  lr: 0.0015984  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:46:18 d2.utils.events]: \u001b[0m eta: 5:24:02  iter: 99  total_loss: 1.809  loss_cls: 0.5673  loss_box_reg: 0.6321  loss_mask: 0.3099  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.2099  total_val_loss: 1.762  val_loss_cls: 0.532  val_loss_box_reg: 0.64  val_loss_mask: 0.2958  val_loss_rpn_cls: 0.09761  val_loss_rpn_loc: 0.1886  time: 6.6478  data_time: 1.8329  lr: 0.001998  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:49:27 d2.utils.events]: \u001b[0m eta: 5:15:37  iter: 119  total_loss: 1.617  loss_cls: 0.4966  loss_box_reg: 0.5575  loss_mask: 0.2827  loss_rpn_cls: 0.07603  loss_rpn_loc: 0.2017  total_val_loss: 1.562  val_loss_cls: 0.4731  val_loss_box_reg: 0.5554  val_loss_mask: 0.2775  val_loss_rpn_cls: 0.08016  val_loss_rpn_loc: 0.177  time: 6.6210  data_time: 1.5857  lr: 0.0023976  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:52:30 d2.utils.events]: \u001b[0m eta: 5:12:25  iter: 139  total_loss: 1.559  loss_cls: 0.4652  loss_box_reg: 0.529  loss_mask: 0.2862  loss_rpn_cls: 0.08203  loss_rpn_loc: 0.2092  total_val_loss: 1.511  val_loss_cls: 0.4513  val_loss_box_reg: 0.5183  val_loss_mask: 0.2749  val_loss_rpn_cls: 0.08817  val_loss_rpn_loc: 0.1759  time: 6.5538  data_time: 1.4728  lr: 0.0027972  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:55:43 d2.utils.events]: \u001b[0m eta: 5:11:35  iter: 159  total_loss: 1.463  loss_cls: 0.4194  loss_box_reg: 0.5065  loss_mask: 0.2671  loss_rpn_cls: 0.07004  loss_rpn_loc: 0.1919  total_val_loss: 1.414  val_loss_cls: 0.4079  val_loss_box_reg: 0.5012  val_loss_mask: 0.2627  val_loss_rpn_cls: 0.08121  val_loss_rpn_loc: 0.1657  time: 6.5795  data_time: 1.8996  lr: 0.0031968  max_mem: 9046M\n",
            "\u001b[32m[04/01 11:58:59 d2.utils.events]: \u001b[0m eta: 5:10:31  iter: 179  total_loss: 1.431  loss_cls: 0.4235  loss_box_reg: 0.4981  loss_mask: 0.263  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1952  total_val_loss: 1.388  val_loss_cls: 0.3964  val_loss_box_reg: 0.4883  val_loss_mask: 0.2566  val_loss_rpn_cls: 0.07036  val_loss_rpn_loc: 0.1675  time: 6.5945  data_time: 1.7296  lr: 0.0035964  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:02:18 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n",
            "\u001b[32m[04/01 12:02:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/01 12:02:18 d2.data.common]: \u001b[0mSerializing 34 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 12:02:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 12:02:18 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[04/01 12:02:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 34 images\n",
            "\u001b[32m[04/01 12:02:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/34. 0.5583 s / img. ETA=0:00:42\n",
            "\u001b[32m[04/01 12:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 14/34. 0.5549 s / img. ETA=0:00:36\n",
            "\u001b[32m[04/01 12:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 17/34. 0.5567 s / img. ETA=0:00:30\n",
            "\u001b[32m[04/01 12:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 20/34. 0.5598 s / img. ETA=0:00:25\n",
            "\u001b[32m[04/01 12:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 23/34. 0.5622 s / img. ETA=0:00:20\n",
            "\u001b[32m[04/01 12:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 26/34. 0.5640 s / img. ETA=0:00:14\n",
            "\u001b[32m[04/01 12:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 29/34. 0.5645 s / img. ETA=0:00:09\n",
            "\u001b[32m[04/01 12:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 32/34. 0.5640 s / img. ETA=0:00:03\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:54.122454 (1.866292 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:16 (0.564557 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.709\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.471\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.465\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 43.567 | 70.899 | 47.054 | 5.568 | 29.906 | 55.996 |\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 50.656 | pouch      | 37.374 | box        | 43.566 |\n",
            "| icebox     | 42.670 |            |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.517\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 47.741 | 71.402 | 51.656 | 4.580 | 27.324 | 64.345 |\n",
            "\u001b[32m[04/01 12:03:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 55.917 | pouch      | 38.997 | box        | 50.104 |\n",
            "| icebox     | 45.945 |            |        |            |        |\n",
            "\u001b[32m[04/01 12:03:23 d2.engine.defaults]: \u001b[0mEvaluation results for skku_unloading_coco_val in csv format:\n",
            "\u001b[32m[04/01 12:03:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/01 12:03:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 12:03:24 d2.evaluation.testing]: \u001b[0mcopypaste: 43.5666,70.8988,47.0537,5.5679,29.9058,55.9957\n",
            "\u001b[32m[04/01 12:03:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/01 12:03:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 12:03:24 d2.evaluation.testing]: \u001b[0mcopypaste: 47.7407,71.4022,51.6563,4.5796,27.3244,64.3451\n",
            "\u001b[32m[04/01 12:03:27 d2.utils.events]: \u001b[0m eta: 5:17:01  iter: 199  total_loss: 1.431  loss_cls: 0.4113  loss_box_reg: 0.4955  loss_mask: 0.2645  loss_rpn_cls: 0.06307  loss_rpn_loc: 0.1961  total_val_loss: 1.358  val_loss_cls: 0.3847  val_loss_box_reg: 0.4777  val_loss_mask: 0.2526  val_loss_rpn_cls: 0.07632  val_loss_rpn_loc: 0.1684  time: 6.6440  data_time: 2.0084  lr: 0.003996  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:06:42 d2.utils.events]: \u001b[0m eta: 5:14:25  iter: 219  total_loss: 1.39  loss_cls: 0.3877  loss_box_reg: 0.4849  loss_mask: 0.2655  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.1924  total_val_loss: 1.318  val_loss_cls: 0.3713  val_loss_box_reg: 0.4557  val_loss_mask: 0.2372  val_loss_rpn_cls: 0.07547  val_loss_rpn_loc: 0.1722  time: 6.6608  data_time: 1.8257  lr: 0.0043956  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:09:52 d2.utils.events]: \u001b[0m eta: 5:08:17  iter: 239  total_loss: 1.392  loss_cls: 0.3687  loss_box_reg: 0.47  loss_mask: 0.26  loss_rpn_cls: 0.06024  loss_rpn_loc: 0.1964  total_val_loss: 1.318  val_loss_cls: 0.3645  val_loss_box_reg: 0.4732  val_loss_mask: 0.2477  val_loss_rpn_cls: 0.07038  val_loss_rpn_loc: 0.1654  time: 6.6384  data_time: 1.6748  lr: 0.0047952  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:13:14 d2.utils.events]: \u001b[0m eta: 5:10:14  iter: 259  total_loss: 1.328  loss_cls: 0.3738  loss_box_reg: 0.4723  loss_mask: 0.2527  loss_rpn_cls: 0.06182  loss_rpn_loc: 0.1821  total_val_loss: 1.307  val_loss_cls: 0.3509  val_loss_box_reg: 0.4597  val_loss_mask: 0.2465  val_loss_rpn_cls: 0.06376  val_loss_rpn_loc: 0.1597  time: 6.6747  data_time: 2.0105  lr: 0.0051948  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:16:22 d2.utils.events]: \u001b[0m eta: 4:59:31  iter: 279  total_loss: 1.301  loss_cls: 0.3524  loss_box_reg: 0.4702  loss_mask: 0.2457  loss_rpn_cls: 0.06008  loss_rpn_loc: 0.1807  total_val_loss: 1.285  val_loss_cls: 0.3509  val_loss_box_reg: 0.4572  val_loss_mask: 0.2363  val_loss_rpn_cls: 0.05676  val_loss_rpn_loc: 0.1673  time: 6.6491  data_time: 1.5405  lr: 0.0055944  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:19:35 d2.utils.events]: \u001b[0m eta: 4:56:31  iter: 299  total_loss: 1.314  loss_cls: 0.3568  loss_box_reg: 0.4605  loss_mask: 0.2403  loss_rpn_cls: 0.05858  loss_rpn_loc: 0.1995  total_val_loss: 1.283  val_loss_cls: 0.3496  val_loss_box_reg: 0.458  val_loss_mask: 0.2302  val_loss_rpn_cls: 0.07236  val_loss_rpn_loc: 0.1726  time: 6.6491  data_time: 1.7344  lr: 0.005994  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:22:46 d2.utils.events]: \u001b[0m eta: 4:55:06  iter: 319  total_loss: 1.311  loss_cls: 0.3458  loss_box_reg: 0.4598  loss_mask: 0.238  loss_rpn_cls: 0.06167  loss_rpn_loc: 0.1947  total_val_loss: 1.241  val_loss_cls: 0.3541  val_loss_box_reg: 0.4412  val_loss_mask: 0.2316  val_loss_rpn_cls: 0.06429  val_loss_rpn_loc: 0.1576  time: 6.6418  data_time: 1.6380  lr: 0.0063936  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:26:04 d2.utils.events]: \u001b[0m eta: 4:53:47  iter: 339  total_loss: 1.288  loss_cls: 0.3474  loss_box_reg: 0.4629  loss_mask: 0.2357  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.1839  total_val_loss: 1.237  val_loss_cls: 0.3418  val_loss_box_reg: 0.4397  val_loss_mask: 0.2259  val_loss_rpn_cls: 0.0603  val_loss_rpn_loc: 0.1656  time: 6.6538  data_time: 1.9462  lr: 0.0067932  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:29:15 d2.utils.events]: \u001b[0m eta: 4:52:37  iter: 359  total_loss: 1.21  loss_cls: 0.3316  loss_box_reg: 0.4423  loss_mask: 0.2319  loss_rpn_cls: 0.05282  loss_rpn_loc: 0.1691  total_val_loss: 1.266  val_loss_cls: 0.3334  val_loss_box_reg: 0.4409  val_loss_mask: 0.2253  val_loss_rpn_cls: 0.06058  val_loss_rpn_loc: 0.168  time: 6.6493  data_time: 1.6407  lr: 0.0071928  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:32:26 d2.utils.events]: \u001b[0m eta: 4:48:48  iter: 379  total_loss: 1.323  loss_cls: 0.3535  loss_box_reg: 0.456  loss_mask: 0.2384  loss_rpn_cls: 0.04703  loss_rpn_loc: 0.1957  total_val_loss: 1.268  val_loss_cls: 0.3433  val_loss_box_reg: 0.4475  val_loss_mask: 0.2349  val_loss_rpn_cls: 0.06671  val_loss_rpn_loc: 0.1724  time: 6.6440  data_time: 1.4878  lr: 0.0075924  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:35:36 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n",
            "\u001b[32m[04/01 12:35:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/01 12:35:36 d2.data.common]: \u001b[0mSerializing 34 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 12:35:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 12:35:36 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[04/01 12:35:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 34 images\n",
            "\u001b[32m[04/01 12:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/34. 0.5335 s / img. ETA=0:00:37\n",
            "\u001b[32m[04/01 12:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 15/34. 0.5093 s / img. ETA=0:00:28\n",
            "\u001b[32m[04/01 12:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 19/34. 0.5189 s / img. ETA=0:00:23\n",
            "\u001b[32m[04/01 12:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 23/34. 0.5199 s / img. ETA=0:00:17\n",
            "\u001b[32m[04/01 12:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 26/34. 0.5231 s / img. ETA=0:00:12\n",
            "\u001b[32m[04/01 12:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 30/34. 0.5231 s / img. ETA=0:00:06\n",
            "\u001b[32m[04/01 12:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 33/34. 0.5241 s / img. ETA=0:00:01\n",
            "\u001b[32m[04/01 12:36:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.751209 (1.577628 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 12:36:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.522512 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.775\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.557\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.662\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.751\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 51.973 | 77.479 | 55.671 | 6.121 | 36.993 | 66.208 |\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 59.496 | pouch      | 44.974 | box        | 54.043 |\n",
            "| icebox     | 49.377 |            |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.498\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 55.178 | 78.326 | 60.383 | 4.840 | 34.076 | 72.058 |\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 63.408 | pouch      | 46.934 | box        | 58.489 |\n",
            "| icebox     | 51.879 |            |        |            |        |\n",
            "\u001b[32m[04/01 12:36:32 d2.engine.defaults]: \u001b[0mEvaluation results for skku_unloading_coco_val in csv format:\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.testing]: \u001b[0mcopypaste: 51.9726,77.4791,55.6711,6.1206,36.9928,66.2077\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 12:36:32 d2.evaluation.testing]: \u001b[0mcopypaste: 55.1778,78.3262,60.3832,4.8396,34.0757,72.0583\n",
            "\u001b[32m[04/01 12:36:35 d2.utils.events]: \u001b[0m eta: 4:46:35  iter: 399  total_loss: 1.285  loss_cls: 0.3316  loss_box_reg: 0.4498  loss_mask: 0.2474  loss_rpn_cls: 0.04993  loss_rpn_loc: 0.1883  total_val_loss: 1.221  val_loss_cls: 0.3315  val_loss_box_reg: 0.4262  val_loss_mask: 0.2229  val_loss_rpn_cls: 0.05841  val_loss_rpn_loc: 0.1616  time: 6.6434  data_time: 1.7075  lr: 0.007992  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:39:46 d2.utils.events]: \u001b[0m eta: 4:44:57  iter: 419  total_loss: 1.221  loss_cls: 0.3341  loss_box_reg: 0.437  loss_mask: 0.2245  loss_rpn_cls: 0.04634  loss_rpn_loc: 0.1797  total_val_loss: 1.216  val_loss_cls: 0.3373  val_loss_box_reg: 0.4238  val_loss_mask: 0.221  val_loss_rpn_cls: 0.05134  val_loss_rpn_loc: 0.1704  time: 6.6416  data_time: 1.7163  lr: 0.0083916  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:42:53 d2.utils.events]: \u001b[0m eta: 4:41:37  iter: 439  total_loss: 1.283  loss_cls: 0.3458  loss_box_reg: 0.4427  loss_mask: 0.2482  loss_rpn_cls: 0.05141  loss_rpn_loc: 0.2052  total_val_loss: 1.236  val_loss_cls: 0.3367  val_loss_box_reg: 0.4274  val_loss_mask: 0.2231  val_loss_rpn_cls: 0.05959  val_loss_rpn_loc: 0.1606  time: 6.6305  data_time: 1.5594  lr: 0.0087912  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:46:08 d2.utils.events]: \u001b[0m eta: 4:40:32  iter: 459  total_loss: 1.171  loss_cls: 0.3076  loss_box_reg: 0.4213  loss_mask: 0.2276  loss_rpn_cls: 0.0461  loss_rpn_loc: 0.182  total_val_loss: 1.221  val_loss_cls: 0.3369  val_loss_box_reg: 0.4127  val_loss_mask: 0.219  val_loss_rpn_cls: 0.06131  val_loss_rpn_loc: 0.1737  time: 6.6348  data_time: 1.5430  lr: 0.0091908  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:49:16 d2.utils.events]: \u001b[0m eta: 4:37:46  iter: 479  total_loss: 1.224  loss_cls: 0.3287  loss_box_reg: 0.4219  loss_mask: 0.2241  loss_rpn_cls: 0.0468  loss_rpn_loc: 0.1893  total_val_loss: 1.174  val_loss_cls: 0.3335  val_loss_box_reg: 0.4195  val_loss_mask: 0.2172  val_loss_rpn_cls: 0.06694  val_loss_rpn_loc: 0.1634  time: 6.6303  data_time: 1.5285  lr: 0.0095904  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:52:23 d2.utils.events]: \u001b[0m eta: 4:35:34  iter: 499  total_loss: 1.231  loss_cls: 0.3282  loss_box_reg: 0.4355  loss_mask: 0.2255  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.1965  total_val_loss: 1.199  val_loss_cls: 0.33  val_loss_box_reg: 0.4173  val_loss_mask: 0.2187  val_loss_rpn_cls: 0.06354  val_loss_rpn_loc: 0.163  time: 6.6243  data_time: 1.6064  lr: 0.00999  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:55:36 d2.utils.events]: \u001b[0m eta: 4:33:22  iter: 519  total_loss: 1.21  loss_cls: 0.3293  loss_box_reg: 0.4241  loss_mask: 0.2236  loss_rpn_cls: 0.04335  loss_rpn_loc: 0.1799  total_val_loss: 1.252  val_loss_cls: 0.3315  val_loss_box_reg: 0.4188  val_loss_mask: 0.2131  val_loss_rpn_cls: 0.06372  val_loss_rpn_loc: 0.1671  time: 6.6236  data_time: 1.5332  lr: 0.01039  max_mem: 9046M\n",
            "\u001b[32m[04/01 12:58:45 d2.utils.events]: \u001b[0m eta: 4:31:09  iter: 539  total_loss: 1.196  loss_cls: 0.331  loss_box_reg: 0.4319  loss_mask: 0.2197  loss_rpn_cls: 0.04696  loss_rpn_loc: 0.1787  total_val_loss: 1.234  val_loss_cls: 0.3222  val_loss_box_reg: 0.4173  val_loss_mask: 0.2135  val_loss_rpn_cls: 0.05715  val_loss_rpn_loc: 0.1679  time: 6.6180  data_time: 1.5930  lr: 0.010789  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:01:58 d2.utils.events]: \u001b[0m eta: 4:28:25  iter: 559  total_loss: 1.153  loss_cls: 0.3196  loss_box_reg: 0.4183  loss_mask: 0.2152  loss_rpn_cls: 0.04423  loss_rpn_loc: 0.1742  total_val_loss: 1.188  val_loss_cls: 0.3313  val_loss_box_reg: 0.414  val_loss_mask: 0.2227  val_loss_rpn_cls: 0.05641  val_loss_rpn_loc: 0.1695  time: 6.6194  data_time: 1.5690  lr: 0.011189  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:05:10 d2.utils.events]: \u001b[0m eta: 4:27:17  iter: 579  total_loss: 1.137  loss_cls: 0.2993  loss_box_reg: 0.4003  loss_mask: 0.2158  loss_rpn_cls: 0.03856  loss_rpn_loc: 0.1751  total_val_loss: 1.202  val_loss_cls: 0.3246  val_loss_box_reg: 0.4089  val_loss_mask: 0.2123  val_loss_rpn_cls: 0.05848  val_loss_rpn_loc: 0.1609  time: 6.6191  data_time: 1.5787  lr: 0.011588  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:08:23 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n",
            "\u001b[32m[04/01 13:08:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/01 13:08:23 d2.data.common]: \u001b[0mSerializing 34 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 13:08:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 13:08:23 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[04/01 13:08:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 34 images\n",
            "\u001b[32m[04/01 13:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/34. 0.5068 s / img. ETA=0:00:34\n",
            "\u001b[32m[04/01 13:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 16/34. 0.4968 s / img. ETA=0:00:25\n",
            "\u001b[32m[04/01 13:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 20/34. 0.5049 s / img. ETA=0:00:20\n",
            "\u001b[32m[04/01 13:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 24/34. 0.5079 s / img. ETA=0:00:14\n",
            "\u001b[32m[04/01 13:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 28/34. 0.5060 s / img. ETA=0:00:08\n",
            "\u001b[32m[04/01 13:09:13 d2.evaluation.evaluator]: \u001b[0mInference done 32/34. 0.5055 s / img. ETA=0:00:02\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.884235 (1.478767 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.506027 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.577\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.655\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 52.593 | 79.975 | 57.737 | 18.856 | 38.150 | 65.547 |\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 61.003 | pouch      | 44.941 | box        | 55.757 |\n",
            "| icebox     | 48.672 |            |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.804\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.629\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 57.122 | 80.381 | 62.886 | 6.867 | 37.441 | 73.303 |\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 66.160 | pouch      | 46.777 | box        | 61.370 |\n",
            "| icebox     | 54.180 |            |        |            |        |\n",
            "\u001b[32m[04/01 13:09:16 d2.engine.defaults]: \u001b[0mEvaluation results for skku_unloading_coco_val in csv format:\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.testing]: \u001b[0mcopypaste: 52.5934,79.9751,57.7372,18.8564,38.1496,65.5470\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 13:09:16 d2.evaluation.testing]: \u001b[0mcopypaste: 57.1217,80.3814,62.8860,6.8667,37.4409,73.3030\n",
            "\u001b[32m[04/01 13:09:20 d2.utils.events]: \u001b[0m eta: 4:25:36  iter: 599  total_loss: 1.172  loss_cls: 0.31  loss_box_reg: 0.4114  loss_mask: 0.2149  loss_rpn_cls: 0.04378  loss_rpn_loc: 0.1934  total_val_loss: 1.208  val_loss_cls: 0.3194  val_loss_box_reg: 0.4202  val_loss_mask: 0.2217  val_loss_rpn_cls: 0.05651  val_loss_rpn_loc: 0.1775  time: 6.6239  data_time: 1.6716  lr: 0.011988  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:12:31 d2.utils.events]: \u001b[0m eta: 4:23:23  iter: 619  total_loss: 1.198  loss_cls: 0.3039  loss_box_reg: 0.4208  loss_mask: 0.2217  loss_rpn_cls: 0.04563  loss_rpn_loc: 0.1972  total_val_loss: 1.165  val_loss_cls: 0.3218  val_loss_box_reg: 0.4061  val_loss_mask: 0.2075  val_loss_rpn_cls: 0.05717  val_loss_rpn_loc: 0.1692  time: 6.6202  data_time: 1.5281  lr: 0.012388  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:15:43 d2.utils.events]: \u001b[0m eta: 4:21:10  iter: 639  total_loss: 1.217  loss_cls: 0.3105  loss_box_reg: 0.433  loss_mask: 0.2234  loss_rpn_cls: 0.04846  loss_rpn_loc: 0.1964  total_val_loss: 1.166  val_loss_cls: 0.3268  val_loss_box_reg: 0.4137  val_loss_mask: 0.2085  val_loss_rpn_cls: 0.06456  val_loss_rpn_loc: 0.1691  time: 6.6206  data_time: 1.7280  lr: 0.012787  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:18:56 d2.utils.events]: \u001b[0m eta: 4:19:35  iter: 659  total_loss: 1.172  loss_cls: 0.3074  loss_box_reg: 0.4112  loss_mask: 0.2057  loss_rpn_cls: 0.04131  loss_rpn_loc: 0.185  total_val_loss: 1.15  val_loss_cls: 0.3128  val_loss_box_reg: 0.4068  val_loss_mask: 0.2038  val_loss_rpn_cls: 0.05223  val_loss_rpn_loc: 0.163  time: 6.6200  data_time: 1.6365  lr: 0.013187  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:22:10 d2.utils.events]: \u001b[0m eta: 4:16:44  iter: 679  total_loss: 1.094  loss_cls: 0.3023  loss_box_reg: 0.4016  loss_mask: 0.1992  loss_rpn_cls: 0.03701  loss_rpn_loc: 0.1669  total_val_loss: 1.169  val_loss_cls: 0.3264  val_loss_box_reg: 0.4069  val_loss_mask: 0.2043  val_loss_rpn_cls: 0.06183  val_loss_rpn_loc: 0.1722  time: 6.6221  data_time: 1.6913  lr: 0.013586  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:25:19 d2.utils.events]: \u001b[0m eta: 4:13:31  iter: 699  total_loss: 1.163  loss_cls: 0.297  loss_box_reg: 0.409  loss_mask: 0.2153  loss_rpn_cls: 0.03576  loss_rpn_loc: 0.1841  total_val_loss: 1.207  val_loss_cls: 0.3214  val_loss_box_reg: 0.399  val_loss_mask: 0.21  val_loss_rpn_cls: 0.0582  val_loss_rpn_loc: 0.167  time: 6.6174  data_time: 1.4669  lr: 0.013986  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:28:28 d2.utils.events]: \u001b[0m eta: 4:11:19  iter: 719  total_loss: 1.121  loss_cls: 0.3077  loss_box_reg: 0.3985  loss_mask: 0.2125  loss_rpn_cls: 0.03159  loss_rpn_loc: 0.1895  total_val_loss: 1.169  val_loss_cls: 0.3122  val_loss_box_reg: 0.4022  val_loss_mask: 0.211  val_loss_rpn_cls: 0.05972  val_loss_rpn_loc: 0.1659  time: 6.6150  data_time: 1.5364  lr: 0.014386  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:31:44 d2.utils.events]: \u001b[0m eta: 4:08:45  iter: 739  total_loss: 1.151  loss_cls: 0.2972  loss_box_reg: 0.413  loss_mask: 0.2079  loss_rpn_cls: 0.04248  loss_rpn_loc: 0.1805  total_val_loss: 1.186  val_loss_cls: 0.3158  val_loss_box_reg: 0.4023  val_loss_mask: 0.2034  val_loss_rpn_cls: 0.08636  val_loss_rpn_loc: 0.1743  time: 6.6212  data_time: 1.7299  lr: 0.014785  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:34:56 d2.utils.events]: \u001b[0m eta: 4:06:24  iter: 759  total_loss: 1.167  loss_cls: 0.3067  loss_box_reg: 0.4056  loss_mask: 0.2107  loss_rpn_cls: 0.04511  loss_rpn_loc: 0.1836  total_val_loss: 1.182  val_loss_cls: 0.3174  val_loss_box_reg: 0.4006  val_loss_mask: 0.2085  val_loss_rpn_cls: 0.07045  val_loss_rpn_loc: 0.1715  time: 6.6206  data_time: 1.6478  lr: 0.015185  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:38:11 d2.utils.events]: \u001b[0m eta: 4:04:21  iter: 779  total_loss: 1.09  loss_cls: 0.2976  loss_box_reg: 0.39  loss_mask: 0.2014  loss_rpn_cls: 0.04289  loss_rpn_loc: 0.1665  total_val_loss: 1.183  val_loss_cls: 0.3111  val_loss_box_reg: 0.4049  val_loss_mask: 0.2087  val_loss_rpn_cls: 0.06065  val_loss_rpn_loc: 0.176  time: 6.6242  data_time: 1.6593  lr: 0.015584  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:41:20 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n",
            "\u001b[32m[04/01 13:41:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/01 13:41:20 d2.data.common]: \u001b[0mSerializing 34 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 13:41:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 13:41:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[04/01 13:41:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 34 images\n",
            "\u001b[32m[04/01 13:41:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/34. 0.5084 s / img. ETA=0:00:33\n",
            "\u001b[32m[04/01 13:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 16/34. 0.4990 s / img. ETA=0:00:25\n",
            "\u001b[32m[04/01 13:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 20/34. 0.5082 s / img. ETA=0:00:20\n",
            "\u001b[32m[04/01 13:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 24/34. 0.5105 s / img. ETA=0:00:14\n",
            "\u001b[32m[04/01 13:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 28/34. 0.5071 s / img. ETA=0:00:08\n",
            "\u001b[32m[04/01 13:42:10 d2.evaluation.evaluator]: \u001b[0mInference done 32/34. 0.5076 s / img. ETA=0:00:02\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.140087 (1.487589 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.507816 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.551\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.808\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.629\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 55.050 | 80.753 | 62.859 | 9.941 | 40.478 | 69.072 |\n",
            "\u001b[32m[04/01 13:42:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 62.375 | pouch      | 48.680 | box        | 59.072 |\n",
            "| icebox     | 50.074 |            |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.810\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.654\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.816\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 58.723 | 81.036 | 65.386 | 7.242 | 39.278 | 75.164 |\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 66.394 | pouch      | 50.161 | box        | 65.297 |\n",
            "| icebox     | 53.039 |            |        |            |        |\n",
            "\u001b[32m[04/01 13:42:14 d2.engine.defaults]: \u001b[0mEvaluation results for skku_unloading_coco_val in csv format:\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.testing]: \u001b[0mcopypaste: 55.0503,80.7531,62.8595,9.9407,40.4781,69.0722\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 13:42:14 d2.evaluation.testing]: \u001b[0mcopypaste: 58.7227,81.0357,65.3863,7.2421,39.2779,75.1645\n",
            "\u001b[32m[04/01 13:42:17 d2.utils.events]: \u001b[0m eta: 4:02:30  iter: 799  total_loss: 1.095  loss_cls: 0.2875  loss_box_reg: 0.3953  loss_mask: 0.2022  loss_rpn_cls: 0.04125  loss_rpn_loc: 0.1799  total_val_loss: 1.137  val_loss_cls: 0.3067  val_loss_box_reg: 0.39  val_loss_mask: 0.203  val_loss_rpn_cls: 0.05058  val_loss_rpn_loc: 0.1576  time: 6.6223  data_time: 1.5330  lr: 0.015984  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:45:25 d2.utils.events]: \u001b[0m eta: 4:01:14  iter: 819  total_loss: 1.131  loss_cls: 0.2788  loss_box_reg: 0.3885  loss_mask: 0.2088  loss_rpn_cls: 0.04024  loss_rpn_loc: 0.1941  total_val_loss: 1.178  val_loss_cls: 0.3199  val_loss_box_reg: 0.4139  val_loss_mask: 0.2058  val_loss_rpn_cls: 0.05647  val_loss_rpn_loc: 0.1691  time: 6.6182  data_time: 1.4374  lr: 0.016384  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:48:34 d2.utils.events]: \u001b[0m eta: 3:59:14  iter: 839  total_loss: 1.133  loss_cls: 0.2948  loss_box_reg: 0.4132  loss_mask: 0.2067  loss_rpn_cls: 0.0358  loss_rpn_loc: 0.1748  total_val_loss: 1.145  val_loss_cls: 0.3188  val_loss_box_reg: 0.3957  val_loss_mask: 0.2012  val_loss_rpn_cls: 0.05234  val_loss_rpn_loc: 0.1652  time: 6.6169  data_time: 1.4792  lr: 0.016783  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:51:47 d2.utils.events]: \u001b[0m eta: 3:57:18  iter: 859  total_loss: 1.108  loss_cls: 0.2872  loss_box_reg: 0.389  loss_mask: 0.2022  loss_rpn_cls: 0.03693  loss_rpn_loc: 0.1923  total_val_loss: 1.165  val_loss_cls: 0.3162  val_loss_box_reg: 0.4035  val_loss_mask: 0.2022  val_loss_rpn_cls: 0.06071  val_loss_rpn_loc: 0.1744  time: 6.6183  data_time: 1.7062  lr: 0.017183  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:54:55 d2.utils.events]: \u001b[0m eta: 3:55:05  iter: 879  total_loss: 1.123  loss_cls: 0.2987  loss_box_reg: 0.4001  loss_mask: 0.2086  loss_rpn_cls: 0.0445  loss_rpn_loc: 0.1763  total_val_loss: 1.191  val_loss_cls: 0.3128  val_loss_box_reg: 0.4128  val_loss_mask: 0.2014  val_loss_rpn_cls: 0.06726  val_loss_rpn_loc: 0.165  time: 6.6147  data_time: 1.6435  lr: 0.017582  max_mem: 9046M\n",
            "\u001b[32m[04/01 13:58:03 d2.utils.events]: \u001b[0m eta: 3:52:36  iter: 899  total_loss: 1.17  loss_cls: 0.3057  loss_box_reg: 0.4197  loss_mask: 0.2152  loss_rpn_cls: 0.03635  loss_rpn_loc: 0.1965  total_val_loss: 1.171  val_loss_cls: 0.3186  val_loss_box_reg: 0.4067  val_loss_mask: 0.2049  val_loss_rpn_cls: 0.05292  val_loss_rpn_loc: 0.1681  time: 6.6112  data_time: 1.5909  lr: 0.017982  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:01:15 d2.utils.events]: \u001b[0m eta: 3:50:23  iter: 919  total_loss: 1.108  loss_cls: 0.2905  loss_box_reg: 0.3968  loss_mask: 0.2071  loss_rpn_cls: 0.03798  loss_rpn_loc: 0.1916  total_val_loss: 1.15  val_loss_cls: 0.3057  val_loss_box_reg: 0.4017  val_loss_mask: 0.2052  val_loss_rpn_cls: 0.06593  val_loss_rpn_loc: 0.1697  time: 6.6105  data_time: 1.8441  lr: 0.018382  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:04:21 d2.utils.events]: \u001b[0m eta: 3:47:16  iter: 939  total_loss: 1.094  loss_cls: 0.2896  loss_box_reg: 0.3877  loss_mask: 0.1985  loss_rpn_cls: 0.03902  loss_rpn_loc: 0.174  total_val_loss: 1.146  val_loss_cls: 0.3132  val_loss_box_reg: 0.4064  val_loss_mask: 0.2007  val_loss_rpn_cls: 0.06428  val_loss_rpn_loc: 0.1601  time: 6.6048  data_time: 1.3752  lr: 0.018781  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:07:35 d2.utils.events]: \u001b[0m eta: 3:45:03  iter: 959  total_loss: 1.134  loss_cls: 0.282  loss_box_reg: 0.3996  loss_mask: 0.2104  loss_rpn_cls: 0.04147  loss_rpn_loc: 0.1859  total_val_loss: 1.177  val_loss_cls: 0.312  val_loss_box_reg: 0.408  val_loss_mask: 0.1998  val_loss_rpn_cls: 0.0485  val_loss_rpn_loc: 0.1715  time: 6.6075  data_time: 1.6812  lr: 0.019181  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:10:42 d2.utils.events]: \u001b[0m eta: 3:42:43  iter: 979  total_loss: 1.081  loss_cls: 0.2858  loss_box_reg: 0.3862  loss_mask: 0.2036  loss_rpn_cls: 0.03775  loss_rpn_loc: 0.1762  total_val_loss: 1.185  val_loss_cls: 0.3166  val_loss_box_reg: 0.4047  val_loss_mask: 0.2026  val_loss_rpn_cls: 0.0622  val_loss_rpn_loc: 0.1711  time: 6.6033  data_time: 1.6249  lr: 0.01958  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:13:53 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n",
            "\u001b[32m[04/01 14:13:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/01 14:13:53 d2.data.common]: \u001b[0mSerializing 34 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 14:13:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 14:13:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[04/01 14:13:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 34 images\n",
            "\u001b[32m[04/01 14:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/34. 0.4724 s / img. ETA=0:00:29\n",
            "\u001b[32m[04/01 14:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 16/34. 0.4665 s / img. ETA=0:00:22\n",
            "\u001b[32m[04/01 14:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 20/34. 0.4740 s / img. ETA=0:00:17\n",
            "\u001b[32m[04/01 14:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 24/34. 0.4768 s / img. ETA=0:00:12\n",
            "\u001b[32m[04/01 14:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 29/34. 0.4726 s / img. ETA=0:00:06\n",
            "\u001b[32m[04/01 14:14:38 d2.evaluation.evaluator]: \u001b[0mInference done 33/34. 0.4767 s / img. ETA=0:00:01\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.233340 (1.283908 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.475664 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.539\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.791\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.613\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 53.942 | 79.059 | 61.342 | 8.861 | 40.153 | 67.043 |\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 62.277 | pouch      | 46.237 | box        | 57.120 |\n",
            "| icebox     | 50.132 |            |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 14:14:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.572\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.788\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.636\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 57.172 | 78.808 | 63.583 | 7.650 | 37.663 | 72.922 |\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 66.259 | pouch      | 47.640 | box        | 61.790 |\n",
            "| icebox     | 52.999 |            |        |            |        |\n",
            "\u001b[32m[04/01 14:14:40 d2.engine.defaults]: \u001b[0mEvaluation results for skku_unloading_coco_val in csv format:\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.testing]: \u001b[0mcopypaste: 53.9416,79.0594,61.3422,8.8605,40.1526,67.0430\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 14:14:40 d2.evaluation.testing]: \u001b[0mcopypaste: 57.1719,78.8080,63.5831,7.6496,37.6631,72.9220\n",
            "\u001b[32m[04/01 14:14:43 d2.utils.events]: \u001b[0m eta: 3:40:30  iter: 999  total_loss: 1.142  loss_cls: 0.2933  loss_box_reg: 0.3906  loss_mask: 0.2098  loss_rpn_cls: 0.0425  loss_rpn_loc: 0.1902  total_val_loss: 1.144  val_loss_cls: 0.3091  val_loss_box_reg: 0.3989  val_loss_mask: 0.1927  val_loss_rpn_cls: 0.05245  val_loss_rpn_loc: 0.1717  time: 6.6051  data_time: 1.6129  lr: 0.01998  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:17:54 d2.utils.events]: \u001b[0m eta: 3:38:26  iter: 1019  total_loss: 1.142  loss_cls: 0.3077  loss_box_reg: 0.397  loss_mask: 0.2124  loss_rpn_cls: 0.03726  loss_rpn_loc: 0.1861  total_val_loss: 1.179  val_loss_cls: 0.3154  val_loss_box_reg: 0.4065  val_loss_mask: 0.2054  val_loss_rpn_cls: 0.06568  val_loss_rpn_loc: 0.1717  time: 6.6062  data_time: 1.6416  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:21:05 d2.utils.events]: \u001b[0m eta: 3:36:09  iter: 1039  total_loss: 1.097  loss_cls: 0.2923  loss_box_reg: 0.3874  loss_mask: 0.2026  loss_rpn_cls: 0.03686  loss_rpn_loc: 0.1786  total_val_loss: 1.158  val_loss_cls: 0.3048  val_loss_box_reg: 0.4031  val_loss_mask: 0.2042  val_loss_rpn_cls: 0.05726  val_loss_rpn_loc: 0.1701  time: 6.6085  data_time: 1.8160  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:24:19 d2.utils.events]: \u001b[0m eta: 3:33:42  iter: 1059  total_loss: 1.052  loss_cls: 0.2574  loss_box_reg: 0.3817  loss_mask: 0.1932  loss_rpn_cls: 0.03787  loss_rpn_loc: 0.1838  total_val_loss: 1.138  val_loss_cls: 0.3076  val_loss_box_reg: 0.3975  val_loss_mask: 0.193  val_loss_rpn_cls: 0.06457  val_loss_rpn_loc: 0.1806  time: 6.6108  data_time: 1.5997  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:27:31 d2.utils.events]: \u001b[0m eta: 3:32:02  iter: 1079  total_loss: 1.148  loss_cls: 0.2934  loss_box_reg: 0.3914  loss_mask: 0.206  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.194  total_val_loss: 1.097  val_loss_cls: 0.3112  val_loss_box_reg: 0.3898  val_loss_mask: 0.1916  val_loss_rpn_cls: 0.05846  val_loss_rpn_loc: 0.1657  time: 6.6110  data_time: 1.6643  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:30:46 d2.utils.events]: \u001b[0m eta: 3:30:27  iter: 1099  total_loss: 1.057  loss_cls: 0.2758  loss_box_reg: 0.3862  loss_mask: 0.1974  loss_rpn_cls: 0.03503  loss_rpn_loc: 0.1652  total_val_loss: 1.135  val_loss_cls: 0.3073  val_loss_box_reg: 0.3828  val_loss_mask: 0.1977  val_loss_rpn_cls: 0.05503  val_loss_rpn_loc: 0.1583  time: 6.6136  data_time: 1.8287  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:34:00 d2.utils.events]: \u001b[0m eta: 3:28:28  iter: 1119  total_loss: 1.053  loss_cls: 0.2813  loss_box_reg: 0.3701  loss_mask: 0.1993  loss_rpn_cls: 0.03309  loss_rpn_loc: 0.1728  total_val_loss: 1.136  val_loss_cls: 0.3073  val_loss_box_reg: 0.4009  val_loss_mask: 0.1964  val_loss_rpn_cls: 0.06398  val_loss_rpn_loc: 0.1598  time: 6.6132  data_time: 1.6526  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:37:16 d2.utils.events]: \u001b[0m eta: 3:26:40  iter: 1139  total_loss: 1.037  loss_cls: 0.2679  loss_box_reg: 0.3733  loss_mask: 0.1887  loss_rpn_cls: 0.03917  loss_rpn_loc: 0.1821  total_val_loss: 1.129  val_loss_cls: 0.3006  val_loss_box_reg: 0.3829  val_loss_mask: 0.1953  val_loss_rpn_cls: 0.05525  val_loss_rpn_loc: 0.1676  time: 6.6161  data_time: 1.7661  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:40:27 d2.utils.events]: \u001b[0m eta: 3:24:20  iter: 1159  total_loss: 1.038  loss_cls: 0.2611  loss_box_reg: 0.3653  loss_mask: 0.1998  loss_rpn_cls: 0.03318  loss_rpn_loc: 0.1864  total_val_loss: 1.125  val_loss_cls: 0.305  val_loss_box_reg: 0.3947  val_loss_mask: 0.2023  val_loss_rpn_cls: 0.05265  val_loss_rpn_loc: 0.1696  time: 6.6154  data_time: 1.6933  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:43:38 d2.utils.events]: \u001b[0m eta: 3:21:35  iter: 1179  total_loss: 1.069  loss_cls: 0.2796  loss_box_reg: 0.367  loss_mask: 0.1974  loss_rpn_cls: 0.03524  loss_rpn_loc: 0.1658  total_val_loss: 1.127  val_loss_cls: 0.302  val_loss_box_reg: 0.387  val_loss_mask: 0.1964  val_loss_rpn_cls: 0.06558  val_loss_rpn_loc: 0.1696  time: 6.6153  data_time: 1.5351  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:46:54 d2.data.datasets.coco]: \u001b[0mLoaded 34 images in COCO format from ./val/val.json\n",
            "\u001b[32m[04/01 14:46:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/01 14:46:54 d2.data.common]: \u001b[0mSerializing 34 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/01 14:46:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.21 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 14:46:54 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "\u001b[32m[04/01 14:46:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 34 images\n",
            "\u001b[32m[04/01 14:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/34. 0.4809 s / img. ETA=0:00:30\n",
            "\u001b[32m[04/01 14:47:17 d2.evaluation.evaluator]: \u001b[0mInference done 16/34. 0.4729 s / img. ETA=0:00:23\n",
            "\u001b[32m[04/01 14:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 20/34. 0.4808 s / img. ETA=0:00:18\n",
            "\u001b[32m[04/01 14:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 24/34. 0.4838 s / img. ETA=0:00:13\n",
            "\u001b[32m[04/01 14:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 28/34. 0.4819 s / img. ETA=0:00:08\n",
            "\u001b[32m[04/01 14:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 32/34. 0.4807 s / img. ETA=0:00:02\n",
            "\u001b[32m[04/01 14:47:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.733562 (1.335640 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 14:47:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.481543 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/01 14:47:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/01 14:47:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.813\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 54.969 | 81.308 | 62.130 | 11.752 | 42.785 | 67.135 |\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 61.869 | pouch      | 45.722 | box        | 59.801 |\n",
            "| icebox     | 52.484 |            |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.823\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.658\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 59.206 | 82.341 | 65.784 | 9.660 | 40.652 | 73.925 |\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| sack       | 67.020 | pouch      | 47.454 | box        | 65.937 |\n",
            "| icebox     | 56.412 |            |        |            |        |\n",
            "\u001b[32m[04/01 14:47:42 d2.engine.defaults]: \u001b[0mEvaluation results for skku_unloading_coco_val in csv format:\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.testing]: \u001b[0mcopypaste: 54.9690,81.3081,62.1303,11.7520,42.7846,67.1348\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/01 14:47:42 d2.evaluation.testing]: \u001b[0mcopypaste: 59.2057,82.3414,65.7842,9.6598,40.6525,73.9246\n",
            "\u001b[32m[04/01 14:47:45 d2.utils.events]: \u001b[0m eta: 3:18:40  iter: 1199  total_loss: 1.041  loss_cls: 0.2654  loss_box_reg: 0.3676  loss_mask: 0.1929  loss_rpn_cls: 0.0364  loss_rpn_loc: 0.1683  total_val_loss: 1.098  val_loss_cls: 0.2959  val_loss_box_reg: 0.3856  val_loss_mask: 0.1915  val_loss_rpn_cls: 0.06383  val_loss_rpn_loc: 0.157  time: 6.6209  data_time: 1.9309  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:50:57 d2.utils.events]: \u001b[0m eta: 3:16:18  iter: 1219  total_loss: 1.061  loss_cls: 0.269  loss_box_reg: 0.371  loss_mask: 0.1964  loss_rpn_cls: 0.03588  loss_rpn_loc: 0.1924  total_val_loss: 1.145  val_loss_cls: 0.2972  val_loss_box_reg: 0.3856  val_loss_mask: 0.1982  val_loss_rpn_cls: 0.0539  val_loss_rpn_loc: 0.1599  time: 6.6201  data_time: 1.5466  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:54:20 d2.utils.events]: \u001b[0m eta: 3:14:56  iter: 1239  total_loss: 1.058  loss_cls: 0.2799  loss_box_reg: 0.3727  loss_mask: 0.1955  loss_rpn_cls: 0.03351  loss_rpn_loc: 0.1762  total_val_loss: 1.123  val_loss_cls: 0.3019  val_loss_box_reg: 0.3878  val_loss_mask: 0.1946  val_loss_rpn_cls: 0.06858  val_loss_rpn_loc: 0.1602  time: 6.6282  data_time: 2.0590  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 14:57:31 d2.utils.events]: \u001b[0m eta: 3:12:16  iter: 1259  total_loss: 0.9823  loss_cls: 0.2575  loss_box_reg: 0.3626  loss_mask: 0.1856  loss_rpn_cls: 0.03385  loss_rpn_loc: 0.1584  total_val_loss: 1.124  val_loss_cls: 0.3033  val_loss_box_reg: 0.3974  val_loss_mask: 0.1993  val_loss_rpn_cls: 0.05997  val_loss_rpn_loc: 0.1643  time: 6.6261  data_time: 1.5429  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 15:00:46 d2.utils.events]: \u001b[0m eta: 3:11:01  iter: 1279  total_loss: 1.028  loss_cls: 0.2564  loss_box_reg: 0.3702  loss_mask: 0.1931  loss_rpn_cls: 0.02933  loss_rpn_loc: 0.1741  total_val_loss: 1.089  val_loss_cls: 0.3039  val_loss_box_reg: 0.377  val_loss_mask: 0.1893  val_loss_rpn_cls: 0.06098  val_loss_rpn_loc: 0.1588  time: 6.6273  data_time: 1.6275  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 15:04:02 d2.utils.events]: \u001b[0m eta: 3:08:53  iter: 1299  total_loss: 1.072  loss_cls: 0.2603  loss_box_reg: 0.3729  loss_mask: 0.1967  loss_rpn_cls: 0.0351  loss_rpn_loc: 0.1743  total_val_loss: 1.12  val_loss_cls: 0.3012  val_loss_box_reg: 0.3884  val_loss_mask: 0.1917  val_loss_rpn_cls: 0.07179  val_loss_rpn_loc: 0.162  time: 6.6294  data_time: 1.7841  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 15:07:15 d2.utils.events]: \u001b[0m eta: 3:06:34  iter: 1319  total_loss: 0.9594  loss_cls: 0.2494  loss_box_reg: 0.3498  loss_mask: 0.1824  loss_rpn_cls: 0.02938  loss_rpn_loc: 0.1574  total_val_loss: 1.131  val_loss_cls: 0.293  val_loss_box_reg: 0.3818  val_loss_mask: 0.1994  val_loss_rpn_cls: 0.06199  val_loss_rpn_loc: 0.1596  time: 6.6292  data_time: 1.7146  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 15:10:33 d2.utils.events]: \u001b[0m eta: 3:04:26  iter: 1339  total_loss: 1.014  loss_cls: 0.2534  loss_box_reg: 0.3541  loss_mask: 0.1929  loss_rpn_cls: 0.03617  loss_rpn_loc: 0.1801  total_val_loss: 1.091  val_loss_cls: 0.2919  val_loss_box_reg: 0.3686  val_loss_mask: 0.1932  val_loss_rpn_cls: 0.06315  val_loss_rpn_loc: 0.1603  time: 6.6321  data_time: 1.6954  lr: 0.02  max_mem: 9046M\n",
            "\u001b[32m[04/01 15:13:44 d2.utils.events]: \u001b[0m eta: 3:02:07  iter: 1359  total_loss: 1.023  loss_cls: 0.2537  loss_box_reg: 0.35  loss_mask: 0.189  loss_rpn_cls: 0.03535  loss_rpn_loc: 0.1753  total_val_loss: 1.12  val_loss_cls: 0.2945  val_loss_box_reg: 0.3777  val_loss_mask: 0.1948  val_loss_rpn_cls: 0.05771  val_loss_rpn_loc: 0.1604  time: 6.6314  data_time: 1.7771  lr: 0.02  max_mem: 9046M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XhCvQVsKcs6"
      },
      "source": [
        "!zip -r output.zip output\n",
        "from google.colab import files\n",
        "files.download('output.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvC61lS9VptR"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"skku_unloading_coco_test\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfLx83yVaOEP"
      },
      "source": [
        "Do evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKjmc5-aaNJS"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"skku_unloading_coco_test\", cfg, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"skku_unloading_coco_test\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "import random\n",
        "\n",
        "for d in random.sample(skku_test_dataset_dicts, 5):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=skku_test_metadata, \n",
        "                   scale=0.4, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bo0cypwllj"
      },
      "source": [
        "skku_train_metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6lYrCqLLLW"
      },
      "source": [
        "## Benchmark inference speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxRHYcAC_Z0f"
      },
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vm2paQxDUMn"
      },
      "source": [
        "# Evaluate performance using pyCOCOtools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFMOqBbWEh5v"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go3Y1NuoDr2d"
      },
      "source": [
        "from pycocotools.coco import COCO \n",
        "from pycocotools.cocoeval import COCOeval \n",
        "import numpy as np \n",
        "import skimage.io as io \n",
        "import pylab,json \n",
        "from tempfile import NamedTemporaryFile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtr1AwIRLxLr"
      },
      "source": [
        "def xyxy2xywh(bbox):\n",
        "        \"\"\"Convert ``xyxy`` style bounding boxes to ``xywh`` style for COCO\n",
        "        evaluation.\n",
        "\n",
        "        Args:\n",
        "            bbox (numpy.ndarray): The bounding boxes, shape (4, ), in\n",
        "                ``xyxy`` order.\n",
        "\n",
        "        Returns:\n",
        "            list[float]: The converted bounding boxes, in ``xywh`` order.\n",
        "        \"\"\"\n",
        "\n",
        "        _bbox = bbox.tolist()\n",
        "        return [\n",
        "            _bbox[0],\n",
        "            _bbox[1],\n",
        "            _bbox[2] - _bbox[0],\n",
        "            _bbox[3] - _bbox[1],\n",
        "        ] \n",
        "\n",
        "import numpy as np                                 # (pip install numpy)\n",
        "from skimage import measure                        # (pip install scikit-image)\n",
        "from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n",
        "\n",
        "def create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd, bbox):\n",
        "    # Find contours (boundary lines) around each sub-mask\n",
        "    # Note: there could be multiple contours if the object\n",
        "    # is partially occluded. (E.g. an elephant behind a tree)\n",
        "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
        "\n",
        "    segmentations = []\n",
        "    polygons = []\n",
        "    #print(len(contours))\n",
        "    for contour in contours:\n",
        "        # Flip from (row, col) representation to (x, y)\n",
        "        # and subtract the padding pixel\n",
        "        for i in range(len(contour)):\n",
        "            row, col = contour[i]\n",
        "            contour[i] = (col - 1, row - 1)\n",
        "\n",
        "        # Make a polygon and simplify it\n",
        "        poly = Polygon(contour)\n",
        "        poly = poly.simplify(1.0, preserve_topology=False)\n",
        "        polygons.append(poly)\n",
        "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
        "        segmentations.append(segmentation)\n",
        "\n",
        "    # Combine the polygons to calculate the bounding box and area\n",
        "    multi_poly = MultiPolygon(polygons)\n",
        "    #x, y, max_x, max_y = multi_poly.bounds\n",
        "    #width = max_x - x\n",
        "    #height = max_y - y\n",
        "    #bbox = (x, y, width, height)\n",
        "    area = multi_poly.area\n",
        "\n",
        "    annotation = {\n",
        "        'segmentation': segmentations,\n",
        "        'iscrowd': is_crowd,\n",
        "        'image_id': image_id,\n",
        "        'category_id': category_id,\n",
        "        'id': annotation_id,\n",
        "        'bbox': bbox,\n",
        "        'area': area\n",
        "    }\n",
        "\n",
        "    return segmentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJR-1DByIlRc"
      },
      "source": [
        "# format all outputs into a list of dicts compatible with COCO\n",
        "\n",
        "import pycocotools.mask as mask_util\n",
        "\n",
        "#instances = outputs['instances']\n",
        "#instances.pred_masks_rle = [mask_util.encode(np.asfortranarray(mask)) for mask in instances.pred_masks]\n",
        "#for rle in instances.pred_masks_rle:\n",
        "#    rle['counts'] = rle['counts'].decode('utf-8')\n",
        "#instances.remove('pred_masks')\n",
        "\n",
        "# TO TEST INVERT CONVERSION\n",
        "#instances.pred_masks = np.stack([mask_util.decode(rle) for rle in instances.pred_masks_rle])\n",
        "\n",
        "#Inspired from\n",
        "# https://www.immersivelimit.com/create-coco-annotations-from-scratch\n",
        "\n",
        "detection_res = []\n",
        "is_crowd = 0\n",
        "for k, d in enumerate(skku_test_dataset_dicts):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    outputs = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    bboxes = outputs.pred_boxes\n",
        "    scores = outputs.scores\n",
        "    classes = outputs.pred_classes\n",
        "    masks = outputs.pred_masks\n",
        " \n",
        "    #print(\"Image: \",k,\"has {} masks\".format(masks.shape[0]))\n",
        "\n",
        "    #for i,(bbox, score, class_) in enumerate(zip(bboxes, scores, classes)):\n",
        "    #  #print(i,bbox.tolist(), score.item(), class_.item(), d[\"image_id\"])\n",
        "    #  annotations = []\n",
        "    #  for j, mask in enumerate(masks):\n",
        "    #    #category_id = category_ids[image_id][color]\n",
        "    #    annotation = create_sub_mask_annotation(mask, d[\"image_id\"], class_, j, is_crowd, xyxy2xywh(bbox))\n",
        "    #    annotations.append(annotation)\n",
        "    #  #annotation_id += 1\n",
        "    #  #image_id += 1\n",
        "\n",
        "\n",
        "    for i,(bbox, score, class_, mask) in enumerate(zip(bboxes, scores, classes, masks)):\n",
        "\n",
        "      annotation = create_sub_mask_annotation(mask, d[\"image_id\"], class_, i, is_crowd, xyxy2xywh(bbox))\n",
        "      #annotations.append(annotation)\n",
        "\n",
        "      detection_res.append({\n",
        "          'score': score.item(),\n",
        "          'category_id': class_.item(),\n",
        "          'bbox': xyxy2xywh(bbox),\n",
        "          'image_id': d[\"image_id\"],\n",
        "          'segmentation': annotation\n",
        "      })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tg4z4qOIuOa"
      },
      "source": [
        "print(detection_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHuWIDgMIKbF"
      },
      "source": [
        "# json file in coco format, original annotation data\n",
        "anno_file = '/content/test/test.json'\n",
        "coco_gt = COCO(anno_file)\n",
        " \n",
        " # Use GT box as prediction box for calculation, the purpose is to get detection_res\n",
        "\n",
        "\"\"\"\n",
        "detection_res = []\n",
        "with open(anno_file, 'r') as f:\n",
        "    json_file = json.load(f)\n",
        "annotations = json_file['annotations']\n",
        "detection_res = []\n",
        "for i, anno in enumerate(annotations):\n",
        "    detection_res.append({\n",
        "        'score': 1,\n",
        "        'category_id': anno['category_id'],\n",
        "        'bbox': anno['bbox'],\n",
        "        'image_id': anno['image_id']\n",
        "    })\n",
        "    if i < 1 :\n",
        "      print( anno['category_id'], anno['image_id'])\n",
        "\"\"\"\n",
        " \n",
        "with NamedTemporaryFile(suffix='.json') as tf:\n",
        "         # Due to subsequent needs, first convert detection_res to binary and then write it to the json file\n",
        "    content = json.dumps(detection_res).encode(encoding='utf-8')\n",
        "    tf.write(content)\n",
        "    res_path = tf.name\n",
        " \n",
        "         # loadRes will generate a new COCO type instance based on coco_gt and return\n",
        "    coco_dt = coco_gt.loadRes(res_path)\n",
        " \n",
        "    cocoEval = COCOeval(coco_gt, coco_dt, 'segm')  # use 'bbox' for bbox mAP or 'segm' for instance segmentation mAP\n",
        "    cocoEval.evaluate()\n",
        "    cocoEval.accumulate()\n",
        "    cocoEval.summarize()\n",
        " \n",
        "print(cocoEval.stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EC_1aCOWok"
      },
      "source": [
        "#mAP\n",
        "mean_ap = cocoEval.stats[0].item()  # stats[0] records AP@[0.5:0.95]\n",
        "print(\"mAP: \", mean_ap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF9VgUouISMK"
      },
      "source": [
        "print(coco_gt.getAnnIds())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5EMtkDLv1W5"
      },
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "experiment_folder = './output/'\n",
        "\n",
        "def load_json_arr(json_path):\n",
        "    lines = []\n",
        "    with open(json_path, 'r') as f:\n",
        "        for line in f:\n",
        "            lines.append(json.loads(line))\n",
        "    return lines\n",
        "\n",
        "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Iteration')\n",
        "ax1.set_ylabel('Loss')\n",
        "print(len(experiment_metrics))\n",
        "print(experiment_metrics[0].keys())\n",
        "\n",
        "ax1.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'total_loss' in x], \n",
        "    [x['total_loss'] for x in experiment_metrics if 'total_loss' in x], color=\"black\", label=\"Total Loss\")\n",
        "ax1.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'total_val_loss' in x], \n",
        "    [x['total_val_loss'] for x in experiment_metrics if 'total_val_loss' in x], color=\"red\", label=\"Val Loss\")\n",
        "    \n",
        "ax1.tick_params(axis='y')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "color = 'tab:orange'\n",
        "ax2.set_ylabel('AP')\n",
        "ax2.plot(\n",
        "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
        "    [x['bbox/AP'] for x in experiment_metrics if 'bbox/AP' in x], color=color, label=\"AP\")\n",
        "ax2.tick_params(axis='y')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}